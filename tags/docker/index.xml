<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Docker on Popstas</title>
    <link>http://blog.popstas.ru/tags/docker/index.xml</link>
    <description>Recent content in Docker on Popstas</description>
    <generator>Hugo -- gohugo.io</generator>
    <language>ru-ru</language>
    <atom:link href="http://blog.popstas.ru/tags/docker/index.xml" rel="self" type="application/rss+xml" />
    
    <item>
      <title>Мой процесс написания ansible роли с Molecule и Gitlab CI</title>
      <link>http://blog.popstas.ru/blog/2017/03/08/develop-ansible-roles-with-molecule-and-gitlab-ci/</link>
      <pubDate>Wed, 08 Mar 2017 01:00:00 +0000</pubDate>
      
      <guid>http://blog.popstas.ru/blog/2017/03/08/develop-ansible-roles-with-molecule-and-gitlab-ci/</guid>
      <description>&lt;p&gt;Опишу процесс, к которому я пришел на данный момент.&lt;/p&gt;

&lt;p&gt;TODO: concurrent
TODO: несколько дистрибов&lt;/p&gt;

&lt;h4 id=&#34;особенности&#34;&gt;Особенности&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;Стремление не писать роли&lt;/li&gt;
&lt;li&gt;Постепенное ужесточение требований при написании, от &amp;ldquo;Лишь бы прошло с 10 раза&amp;rdquo; к &amp;ldquo;Скорее всего Travis пройдет с первого раза&amp;rdquo;&lt;/li&gt;
&lt;li&gt;Тестирование на разных машинах&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.popstas.ru/images/2017-03/iterations.png&#34; /&gt;
&lt;/p&gt;

&lt;h2 id=&#34;поиск-роли&#34;&gt;Поиск роли&lt;/h2&gt;

&lt;p&gt;Во-первых, я ищу готовую роль. Писать свою роль с нуля я считаю неправильным.
При поиске я во-первых иду смотреть, если ли такая роль
у &lt;a href=&#34;https://github.com/geerlingguy&#34; target=&#34;_blank&#34;&gt;geerlingguy&lt;/a&gt; или &lt;a href=&#34;https://github.com/debops&#34; target=&#34;_blank&#34;&gt;debops&lt;/a&gt;.
Но роли debops я еще не форкал, слишком они навороченные и зависимые от других debops-ролей.&lt;/p&gt;

&lt;h4 id=&#34;критерии-выбора-роли&#34;&gt;Критерии выбора роли&lt;/h4&gt;

&lt;ul&gt;
&lt;li&gt;авторитет разработчика роли, какой у него опыт&lt;/li&gt;
&lt;li&gt;количество звездочек&lt;/li&gt;
&lt;li&gt;наличие тестов&lt;/li&gt;
&lt;li&gt;уровень шаблонизации роли (сколько переменных есть в &lt;code&gt;defaults/main.yml&lt;/code&gt;, а сколько вшито в шаблоны)&lt;/li&gt;
&lt;li&gt;обновляемость (пульс проекта), особенно важно для обновляемого и сложного софта, менее важно для базовых ролей&lt;/li&gt;
&lt;li&gt;количество кода, универсальность: если роль популярная и ставится на все системы, есть опасность, что в ней будет много лишнего&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Итак, роль найдена и форкнута.&lt;/p&gt;

&lt;h2 id=&#34;отладка-роли&#34;&gt;Отладка роли&lt;/h2&gt;

&lt;h3 id=&#34;converge&#34;&gt;Converge&lt;/h3&gt;

&lt;p&gt;При написании роли я пользуюсь в основном &lt;code&gt;molecule converge&lt;/code&gt; - команда создает машину, если ее еще нет,
прогоняет плейбук, больше ничего не делает.&lt;/p&gt;

&lt;p&gt;Конечно, в начале роль всегда сломана. Если непонятна причина, я иду внутрь контейнера через &lt;code&gt;molecule login&lt;/code&gt; -
так можно залезть внуть машины и посмотреть, что там пошло не так.
Можно не запуская роль сначала научиться делать правильные действия в контейнере, после чего записать это в виде тасков,
уничтожить контейнер и прогнать заново (&lt;code&gt;molecule test&lt;/code&gt; на этом этапе подходит, хоть он и убьет контейнер, как перед прохождением,
так и после успешного прохождения тестов, можно не волноваться: успешного прохождения скорее всего пока не будет).&lt;/p&gt;

&lt;p&gt;Если форкнута нормальная роль, &lt;code&gt;converge&lt;/code&gt; проходится быстро.&lt;/p&gt;

&lt;h3 id=&#34;validate&#34;&gt;Validate&lt;/h3&gt;

&lt;p&gt;Когда основной сценарий проходит, я запускаю &lt;code&gt;molecule validate&lt;/code&gt;, исправляю ошибки, которые нашел &lt;code&gt;ansible-lint&lt;/code&gt; и помечаю таски,
которые не хочу править, тегом &lt;code&gt;skip_ansible_lint&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;После этого пишу тесты &lt;code&gt;testinfra&lt;/code&gt; (хотя такое у меня бывает редко), проверяю тем же &lt;code&gt;molecule validate&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;test&#34;&gt;Test&lt;/h3&gt;

&lt;p&gt;В конце перепроверяю все через &lt;code&gt;molecule test&lt;/code&gt;, правлю сломанную идемпотентность, при необходимости вношу правки в &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;
и &lt;code&gt;molecule.yml&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;После этого можно проверить сборку, запустив одноразовый раннер локально, это очень удобно, позволяет исключить ошибки на стороне Gitlab CI.
Параметры раннера те же, что и при регистрации на сервере, последним аргументом идет секция из &lt;code&gt;.gitlab-ci.yml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gitlab-runner exec docker \
    --docker-image popstas/ubuntu-molecule:latest \
    --docker-volumes /var/run/docker.sock:/var/run/docker.sock \
    test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;На самом деле у меня еще пробрасывается файл 00aptproxy, у меня во всех тестовых сетях стоит &lt;code&gt;apt-cacher-ng&lt;/code&gt;, который позволяет
ускорять прогон ролей и не гонять трафик зря. Об этом подробнее
&lt;a href=&#34;http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/&#34;&gt;я писал недавно&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;Эта команда создаст раннер с указанным образом и запустит в нем секцию test.&lt;br /&gt;
Чтобы в системе появился &lt;code&gt;gitlab-runner&lt;/code&gt;, нужно поставить &lt;code&gt;gitlab-ci-multi-runner&lt;/code&gt; и Docker, больше кажется ничего не надо.&lt;/p&gt;

&lt;p&gt;Когда и это сработало, я пушу на внутренний сервер и на Github и жду, что мне ответят два CI.
Если после всего это тесты не проходят, матерюсь и ищу косяки на стороне раннера.&lt;/p&gt;

&lt;p&gt;Чтобы упростить себе этот процесс, я написал скрипт, который делает следующее:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ставит тег на последний коммит (bump version), если тег был, удаляет его и ставит на последний коммит&lt;/li&gt;
&lt;li&gt;логинится на dev-сервер, делает оттуда rsync роли с моего компа, прогоняет тесты на gitlab-runner&lt;/li&gt;
&lt;li&gt;если все прошло успешно, делает push на gitlab и github&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Выглядит это так: я делаю коммит, вызываю команду вроде &lt;code&gt;role-deploy v1.1.0&lt;/code&gt; и занимаюсь своими делами.
А тем временем роль проходит 3 прогона тестов с разных серверов и попадает во все апстримы, в том числе в &lt;code&gt;galaxy.ansible.com&lt;/code&gt;.
А если не попадает, то все равно избавляет от коммитов типа &lt;code&gt;test: please work!&lt;/code&gt;. Можно повесить это на &lt;code&gt;prepush&lt;/code&gt; хук git,
но мне вручную удобнее запускать.&lt;/p&gt;

&lt;h3 id=&#34;dev&#34;&gt;Dev&lt;/h3&gt;

&lt;p&gt;Если все прошло успешно, я пишу плейбук для деплоя, накатываю роль на локальную машину, dev-сервера, продакшен сервера
(если косяки в роли не могут повлиять на их работу), всего набирается 2-5 машин.
После этого в течение 1-2 дней чаще всего находятся недоработки, которые чинятся, после чего роль передеплоится.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Настройка кеширующего прокси apt-cacher-ng для ускорения тестирования ansible ролей с Molecule, Gitlab CI и Docker</title>
      <link>http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/</link>
      <pubDate>Sun, 26 Feb 2017 04:14:00 +0000</pubDate>
      
      <guid>http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/</guid>
      <description>&lt;p&gt;В &lt;a href=&#34;http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/&#34;&gt;предыдущей статье&lt;/a&gt; я настраивал &lt;code&gt;apt-mirror&lt;/code&gt; для тех же целей. У того способа нашлось несколько недостатков.&lt;/p&gt;

&lt;p&gt;В статье ниже описано, как решить ту же проблему, используя &lt;code&gt;apt-cacher-ng&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Tl;dr: на этот раз все получилось, этот способ меня устроил.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.popstas.ru/images/2017-02/apt-cacher-ng.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;настройка-apt-cacher-ng&#34;&gt;Настройка apt-cacher-ng&lt;/h2&gt;

&lt;p&gt;Здесь все довольно просто, проще, чем с &lt;code&gt;apt-mirror&lt;/code&gt;.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;apt-get install apt-cacher-ng
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;В конфиге я задал пароль админа в &lt;code&gt;/etc/apt-cacher-ng/security.conf&lt;/code&gt;, он дает право смотреть подробную статистику по cache-hit.&lt;/p&gt;

&lt;p&gt;В &lt;code&gt;/etc/apt-cacher-ng/acng.conf&lt;/code&gt; интересны следующие строчки:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;code&gt;ExTreshold: 4&lt;/code&gt; - устаревание кеша, в днях. Если файл ни разу не запрашивался дольше указанного времени, он будет удален. Я увеличил до 30 дней&lt;/li&gt;
&lt;li&gt;&lt;code&gt;PassThroughPattern: .*:443&lt;/code&gt; - нужно указать это, чтобы не было проблем с HTTPS репозиториями (об этом ниже).&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;В остальном стандартный конфиг делает следующее:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;запускает веб-сервер для всего мира на &lt;code&gt;0.0.0.0:3142&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;хостит страничку и информацией о сервисе и статистикой на &lt;a href=&#34;http://myserver.ru:3142&#34; target=&#34;_blank&#34;&gt;http://myserver.ru:3142&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;хранит кеши в &lt;code&gt;/var/cache/apt-cacher-ng&lt;/code&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Также нужно отредактировать файл &lt;code&gt;/etc/apt-cacher-ng/backends_ubuntu&lt;/code&gt;, удалив из него лишние зеркала и поставив главное зеркало в начало, иначе рискуете однажды получить 403 ошибку при установке одного из пакетов (об этом чуть ниже). У меня файл такой:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;http://mirror.yandex.ru/ubuntu/
http://archive.ubuntu.com/ubuntu/
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Подробности ремапинга можно почитать &lt;a href=&#34;https://www.unix-ag.uni-kl.de/~bloch/acng/html/config-serv.html&#34; target=&#34;_blank&#34;&gt;в документации&lt;/a&gt;. В 2 словах: когда клиент запрашивает пакет, apt-cacher-ng скачивает его не с репозитория, который прописан на клиенте, а с первого зеркала, указанного в файле ремапинга. Второй репозиторий по факту никогда не выбирается.&lt;/p&gt;

&lt;p&gt;После этого можно перезапустить сервис:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;service apt-cacher-ng restart
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Проверяем, что он поднялся, должен открыться урл &lt;code&gt;http://myserver.ru:3142&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;ошибка-403-при-получении-одного-из-пакетов&#34;&gt;Ошибка 403 при получении одного из пакетов&lt;/h3&gt;

&lt;p&gt;Через некоторое время использования я споткнулся об ошибку:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;$ apt-get install php-common -y
Reading package lists... Done
Building dependency tree
Reading state information... Done
The following additional packages will be installed:
  psmisc
The following NEW packages will be installed:
  php-common psmisc
0 upgraded, 2 newly installed, 0 to remove and 7 not upgraded.
Need to get 10.8 kB/58.8 kB of archives.
After this operation, 299 kB of additional disk space will be used.
Err:1 http://archive.ubuntu.com/ubuntu xenial/main amd64 php-common all 1:35ubuntu6
  403  Forbidden
E: Failed to fetch http://archive.ubuntu.com/ubuntu/pool/main/p/php-defaults/php-common_35ubuntu6_all.deb  403  Forbidden

E: Unable to fetch some archives, maybe run apt-get update or try with --fix-missing?
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Я стал разбираться, оказалось, что дело в прокси, если его убрать, все становится нормально.&lt;/p&gt;

&lt;p&gt;Оказалось, что репозиторий по умолчанию, который прописан в &lt;code&gt;/etc/apt-cacher-ng/backends_ubuntu.default&lt;/code&gt; какой-то немного битый и пакет php-common не отдавал. Чтобы этого не произошло, нужно добавить свои репозитории в &lt;code&gt;/etc/apt-cacher-ng/backends_ubuntu&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Solution:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo http://archive.ubuntu.com/ubuntu/ &amp;gt; /etc/apt-cacher-ng/backends_ubuntu
service apt-cacher-ng restart
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;ошибка-403-при-доступе-к-https-репозиториям&#34;&gt;Ошибка 403 при доступе к HTTPS репозиториям&lt;/h3&gt;

&lt;p&gt;В этом месте тоже появляются ошибки, проявляются в ошибках 403 при &lt;code&gt;apt-get update&lt;/code&gt;.
Проблема здесь в том, что apt-cacher-ng не может прочитать зашифрованный трафик от https репозиториев, но все равно пытается. Этого можно избежать двумя способами:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;добавить такие репозитории в исключения&lt;/li&gt;
&lt;li&gt;использовать http репозитории в sources, а потом ремапить их на настоящие репозитории в apt-cacher-ng&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Первый способ позволяет избежать изменения sources для системы-клиента apt-cacher-ng, второй - экономить трафик и для таких репозиториев. Я хочу, чтобы прокси работал максимально прозрачно, поэтому я использую первый способ. За то, какие репозитории обрабатывать, отвечает параметр &lt;code&gt;PassThroughPattern&lt;/code&gt;. Нам нужно исключить из регулярного выражения все HTTPS репозитории.&lt;/p&gt;

&lt;p&gt;Было:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PassThroughPattern: ^bugs.debian.org:443
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Стало:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PassThroughPattern: .*:443
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;О втором способе можно прочитать в &lt;a href=&#34;https://blog.packagecloud.io/eng/2015/05/05/using-apt-cacher-ng-with-ssl-tls/&#34; target=&#34;_blank&#34;&gt;этой статье&lt;/a&gt;.&lt;/p&gt;

&lt;h2 id=&#34;настройка-на-клиентах&#34;&gt;Настройка на клиентах&lt;/h2&gt;

&lt;p&gt;На клиентах нужно добавить один файлик с указанием адреса прокси, &lt;code&gt;sources.list&lt;/code&gt; менять не надо:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &#39;Acquire::http::Proxy &amp;quot;http://myserver.ru:3142&amp;quot;;&#39; &amp;gt; /etc/apt/apt.conf.d/00aptproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;На хосте я этого делать не стал, т.к. у меня там стоит старая Ubuntu 14.04, а тестирую я на Ubuntu 16.04. К слову, apt-cacher-ng это не волнует, он нормально кеширует новые пакеты, не смотря на то, что стоит на старой оси. Как я понимаю, его можно использовать и в смешанном режиме, то есть кешировать пакеты сразу от нескольких версий операционок, но я это не проверял.&lt;/p&gt;

&lt;p&gt;Вместо этого я положил файлик с указанием прокси в отдельную папку, откуда я буду пробрасывать его внутрь тестовых контейнеров:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;echo &#39;Acquire::http::Proxy &amp;quot;http://myserver.ru:3142&amp;quot;;&#39; &amp;gt; /usr/local/src/00aptproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;использование-с-molecule-gitlab-ci-и-travis-ci&#34;&gt;Использование с Molecule, Gitlab CI и Travis CI&lt;/h2&gt;

&lt;p&gt;Не знаю зачем, но роли я тестирую сразу двумя CI: Gitlab и Travis. В связи с этим появляется проблема: нужно на Gitlab CI использовать один кеширующий сервер, при локальном тестировании другой, а для Travis CI убирать его.&lt;/p&gt;

&lt;p&gt;Сложность в том, что Molecule не поддерживает разные конфиги, только умеет использовать в конфигах переменные окружения. Это я и использовал.&lt;/p&gt;

&lt;p&gt;Смысл в том, что на разных CI в контейнер будут пробрасываться разные &lt;code&gt;/etc/apt/apt.conf.d/00aptproxy&lt;/code&gt;, для Travis это будет просто пустой файл.&lt;/p&gt;

&lt;p&gt;&lt;code&gt;.travis.yml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;script:
  - export MOLECULE_APTPROXY_PATH=&amp;quot;$PWD/00aptproxy&amp;quot;
  - touch &amp;quot;$MOLECULE_APTPROXY_PATH&amp;quot;
  - molecule --debug test
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;molecule.yml&lt;/code&gt;:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker:
  containers:
    - name: ansible-role-mysql
      image: ubuntu
      image_version: latest
      volume_mounts:
        - ${MOLECULE_APTPROXY_PATH}:/etc/apt/apt.conf.d/00aptproxy
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;.gitlab-ci.yml&lt;/code&gt; я решил не менять, вместо этого я изменил способ регистрации раннеров в Gitlab CI, используются специальные раннеры с проброшенной переменной окружения:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;gitlab-ci-multi-runner register -n \
  --executor docker \
  --description &amp;quot;Docker at myserver.ru on popstas/ubuntu-molecule&amp;quot; \
  --docker-image &amp;quot;popstas/ubuntu-molecule:latest&amp;quot; \
  --docker-volumes /var/run/docker.sock:/var/run/docker.sock \
  --env &amp;quot;MOLECULE_APTPROXY_PATH=/usr/local/src/00aptproxy&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Это сделано потому, что я еще запускаю локальные раннеры, хотелось сделать так, чтобы &lt;code&gt;.gitlab-ci.yml&lt;/code&gt; подходил во всех случаях.&lt;/p&gt;

&lt;p&gt;На локальной машине можно просто добавить переменные окружения через &lt;code&gt;export&lt;/code&gt; прямо в терминале или добавить их в ваш &lt;code&gt;~/.profile&lt;/code&gt;, тогда можно просто запускать &lt;code&gt;molecule test&lt;/code&gt; и все будет работать.&lt;/p&gt;

&lt;h2 id=&#34;тестирование-скорости&#34;&gt;Тестирование скорости&lt;/h2&gt;

&lt;p&gt;Дополню таблицу из &lt;a href=&#34;http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/&#34;&gt;прошлой статьи&lt;/a&gt;. Естественно, указано время второго прогона apt-cacher-ng для роли, т.к. в первый запуск пакеты еще не скачались, и скорость будет как при использовании стандартного репозитория.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Роль&lt;/th&gt;
&lt;th&gt;archive.ubuntu.org&lt;/th&gt;
&lt;th&gt;apt-mirror&lt;/th&gt;
&lt;th&gt;apt-cacher-ng&lt;/th&gt;
&lt;th&gt;Travis CI:&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ansible-role-common&lt;/td&gt;
&lt;td&gt;8:04&lt;/td&gt;
&lt;td&gt;6:18&lt;/td&gt;
&lt;td&gt;6:30&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;4:32&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-mysql&lt;/td&gt;
&lt;td&gt;3:41&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;3:22&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;3:26&lt;/td&gt;
&lt;td&gt;3:46&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-zsh&lt;/td&gt;
&lt;td&gt;3:16&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2:54&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;2:56&lt;/td&gt;
&lt;td&gt;4:08&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Как видим, в скорости решение с &lt;code&gt;apt-cacher-ng&lt;/code&gt; по сравнению с &lt;code&gt;apt-mirror&lt;/code&gt; почти не теряет. Если не видно разницы, зачем тратить лишние 140 Гб?&lt;/p&gt;

&lt;p&gt;Кстати, скорость тестирования увеличилась и на других способах, которые я описывал в прошлой статье: если тогда разница между способами была 20-30%, то теперь она сократилась до 10-20%. Это говорит о том, что если ничего не делать и пользоваться стандартными удаленными репозиториями, вы будете больше зависеть от внешних факторов.&lt;/p&gt;

&lt;h2 id=&#34;выводы&#34;&gt;Выводы&lt;/h2&gt;

&lt;h3 id=&#34;минусы&#34;&gt;Минусы:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Подходит только для множественного запуска однотипных установок, в моем случае так и есть&lt;/li&gt;
&lt;li&gt;Немного медленнее, чем при использовании зеркала, минусом это назвать сложно, т.к. разница всего 1-3%&lt;/li&gt;
&lt;li&gt;Нужно пробрасывать порт через фаервол, если хотите открыть прокси всему миру, я этого делать не стал :)&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;плюсы&#34;&gt;Плюсы:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;Хранит только нужные пакеты&lt;/li&gt;
&lt;li&gt;Кеширует не только пакеты из стандартного репозитория, но и внешние пакеты, которые вы добавляете в &lt;code&gt;sources.list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;Не требует изменения sources.list&lt;/li&gt;
&lt;li&gt;Проше настраивать&lt;/li&gt;
&lt;li&gt;Не нужен веб-сервер (nginx)&lt;/li&gt;
&lt;li&gt;По умолчанию фаервол закрывает вас&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Как видите, минусы надуманны, а плюсы реальны. На этом история ускорения скачивания пакетов закончена, но остается еще много интересных моментов в тестировании Ansible на Gitlab CI, продолжение следует.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Как я создал и отказался от локального репозитория apt-mirror для Ubuntu для ускорения тестирования ansible ролей</title>
      <link>http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/</link>
      <pubDate>Fri, 24 Feb 2017 17:39:00 +0000</pubDate>
      
      <guid>http://blog.popstas.ru/blog/2017/02/24/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker/</guid>
      <description>&lt;p&gt;При тестировании плейбуков на чистой Ubuntu (а как же еще?) самые большие накладные расходы по времени (субъективно)
и уж точно самые большие по трафику уходят на установку пакетов из системного репозитория. Особенно это заметно, когда видишь, что один и тот же тест Travis CI прогоняет в 1.5 раза быстрее.&lt;/p&gt;

&lt;p&gt;Ниже описано, как создать зеркало из &lt;a href=&#34;http://mirror.yandex.ru/ubuntu&#34; target=&#34;_blank&#34;&gt;http://mirror.yandex.ru/ubuntu&lt;/a&gt; и подружить его с Gitlab CI и molecule.&lt;/p&gt;

&lt;p&gt;Tl;dr: не делайте локальный репозиторий через &lt;code&gt;apt-mirror&lt;/code&gt; для мелких задач, не стоит оно того. Вместо этого нужно поднять кеширующий сервер через &lt;a href=&#34;http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/&#34;&gt;apt-cacher-ng&lt;/a&gt;.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;http://blog.popstas.ru/images/2017-02/apt-mirror.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;настройка-apt-mirror&#34;&gt;Настройка apt-mirror&lt;/h2&gt;

&lt;p&gt;Для синхронизации локального репозитория с основным вариант один - &lt;code&gt;apt-mirror&lt;/code&gt;.
&lt;a href=&#34;https://apt-mirror.github.io&#34; target=&#34;_blank&#34;&gt;Официальный сайт&lt;/a&gt; считает нас умными, поэтому все его инструкции заключаются в 3 строчках:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;apt-get install apt-mirror
nano /etc/apt/mirror.list
sudo apt-mirror
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Все действительно почти так просто. Почти.&lt;/p&gt;

&lt;h3 id=&#34;выбор-самого-быстрого-репозитория&#34;&gt;Выбор самого быстрого репозитория&lt;/h3&gt;

&lt;p&gt;Пока гуглил тему, случайно наткнулся на &lt;a href=&#34;https://hub.docker.com/r/evgeniyklemin/ubuntu-fastest-apt-mirror/&#34; target=&#34;_blank&#34;&gt;инструкцию&lt;/a&gt;, как выбрать самый быстрый репозиторий.
Скорее всего, для нас для всех это будет &lt;a href=&#34;http://mirror.yandex.ru/ubuntu&#34; target=&#34;_blank&#34;&gt;http://mirror.yandex.ru/ubuntu&lt;/a&gt;, но можно в этом убедиться:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;wget -q -nv -O- http://ftp.ru.debian.org/debian/pool/main/n/netselect/netselect_0.3.ds1-26_amd64.deb &amp;gt; /tmp/netselect_0.3.ds1-26_amd64.deb
dpkg -i /tmp/netselect_0.3.ds1-26_amd64.deb
netselect -s3 -t20 &lt;span style=&#34;color: #586E75&#34;&gt;`&lt;/span&gt;wget -q -nv -O- https://launchpad.net/ubuntu/+archivemirrors &lt;span style=&#34;color: #93A1A1&#34;&gt;|&lt;/span&gt; grep -P -B8 &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;statusUP|statusSIX&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #93A1A1&#34;&gt;|&lt;/span&gt; grep -o -P &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;(f|ht)tp.*\&amp;quot;&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #93A1A1&#34;&gt;|&lt;/span&gt; tr &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;&amp;quot;\n&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;  &amp;#39;&lt;/span&gt;&lt;span style=&#34;color: #586E75&#34;&gt;`&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Пакета нет в репозитории Ubuntu, поэтому качаем из репозитория Debian
В результате вы получите список из 3 самых быстрых (по пингу) репозиториев:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;54 http://mirror.yandex.ru/ubuntu/
89 http://ubuntu.volia.net/ubuntu-archive/
124 http://nl.archive.ubuntu.com/ubuntu/
&lt;/code&gt;&lt;/pre&gt;

&lt;h3 id=&#34;конфигурация&#34;&gt;Конфигурация&lt;/h3&gt;

&lt;p&gt;Открываем &lt;code&gt;/etc/apt/mirror.list&lt;/code&gt;.&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;Меняем &lt;code&gt;archive.ubuntu.com&lt;/code&gt; на &lt;code&gt;mirror.yandex.ru&lt;/code&gt;.&lt;/li&gt;
&lt;li&gt;Убираем &lt;code&gt;multiverse&lt;/code&gt; репозиторий (в стандартном Docker контейнере &lt;code&gt;ubuntu&lt;/code&gt; его нет, видимо не очень нужен, зато экономим сразу 13 Гб).&lt;/li&gt;
&lt;li&gt;Меняем путь хранения зеркала, не забывая после этого скопировать пустой скрипт в новое место &lt;code&gt;/var/spool/apt-mirror/var/postmirror.sh&lt;/code&gt;, иначе &lt;code&gt;apt-mirror&lt;/code&gt; будет в конце падать с ошибкой. У меня зеркало будет храниться в &lt;code&gt;/var/backups/apt-mirror&lt;/code&gt; (на диске с бекапами места много)&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Это же в виде команд:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;sed -i /etc/apt/mirror.list &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;s/archive.ubuntu.com/mirror.yandex.ru/g&amp;#39;&lt;/span&gt;
sed -i /etc/apt/mirror.list &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;s/ multiverse//g&amp;#39;&lt;/span&gt;
sed -i /etc/apt/mirror.list &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;s/\/var\/spool\/apt-mirror/\var\/backups\/apt-mirror/g&amp;#39;&lt;/span&gt;
mkdir -p /var/backups/apt-mirror/var
cp /var/spool/apt-mirror/var/postmirror.sh /var/backups/apt-mirror/var
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Добавляем в cron задание по обновлению репозитория, я буду запускать в 1 ночи:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;sed -i &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;s/#0 4/0 1/g&amp;#39;&lt;/span&gt; /etc/cron.d/apt-mirror
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Настраиваем nginx на отдачу репозитория, у меня конфиг такой:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;server &lt;span style=&#34;color: #719e07&#34;&gt;{&lt;/span&gt;
  listen &lt;span style=&#34;color: #2AA198&#34;&gt;80&lt;/span&gt;&lt;span style=&#34;color: #93A1A1&#34;&gt;;&lt;/span&gt;
  server_name mirror.myserver.ru&lt;span style=&#34;color: #93A1A1&#34;&gt;;&lt;/span&gt;
  root /var/backups/apt-mirror/mirror/mirror.yandex.ru&lt;span style=&#34;color: #93A1A1&#34;&gt;;&lt;/span&gt;
  access_log off&lt;span style=&#34;color: #93A1A1&#34;&gt;;&lt;/span&gt;

  location / &lt;span style=&#34;color: #719e07&#34;&gt;{&lt;/span&gt;
    autoindex on&lt;span style=&#34;color: #93A1A1&#34;&gt;;&lt;/span&gt;
  &lt;span style=&#34;color: #719e07&#34;&gt;}&lt;/span&gt;
&lt;span style=&#34;color: #719e07&#34;&gt;}&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Все готово, осталось запустить &lt;code&gt;apt-mirror&lt;/code&gt; и подождать денек: у меня выкачивалось 142 Гб.
Причем обновления тоже будут весить ощутимо, как я понял: через день я запустил apt-mirror еще раз,
он скачал 1.5 Гб.&lt;/p&gt;

&lt;p&gt;Проверяем URL &lt;a href=&#34;http://mirror.myserver.ru/&#34; target=&#34;_blank&#34;&gt;http://mirror.myserver.ru/&lt;/a&gt;, там должен быть доступен каталог &lt;code&gt;ubuntu&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;После этого можете сменить системные репозитории в ваших локальных убунтах и наслаждаться скоростью.&lt;/p&gt;

&lt;p&gt;date = &amp;ldquo;Ошибка&amp;rdquo;
slug = &amp;ldquo;Ошибка/why-you-should-not-use-apt-mirror-for-ansible-tests-in-docker&amp;rdquo;
Хотя нет, насладиться сразу конечно не получилось. По какой-то причине (наверное причина в месте на диске), apt-mirror выкачивает только amd64 пакеты, из-за чего &lt;code&gt;apt-get update&lt;/code&gt; ругается:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;W: The repository &#39;http://apt.myserver.ru/ubuntu xenial-backports Release&#39; does not have a Release file.
W: Failed to fetch http://apt.myserver.ru/ubuntu/dists/xenial/main/binary-i386/Packages: 404  Not Found
W: Failed to fetch http://apt.myserver.ru/ubuntu/dists/xenial-updates/main/binary-i386/Packages: 404  Not Found
E: Some index files failed to download. They have been ignored, or old ones used instead.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Казалось бы ничего страшного, но уверен, что в тестах ненулевой код выхода apt-get будет все останавливать, поэтому придется чинить.&lt;/p&gt;

&lt;p&gt;Ошибка есть на &lt;a href=&#34;https://askubuntu.com/questions/465303/apt-mirror-error/574141&#34; target=&#34;_blank&#34;&gt;askubuntu.com&lt;/a&gt;, спасибо человеку, который предложил решение и негодовал по поводу того, что есть только в &lt;code&gt;man sources.list&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;Решение напрашивается: явно указывать в &lt;code&gt;sources.list&lt;/code&gt;, что в репозитории только amd64 пакеты, то есть вместо:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;deb [ arch=amd64 ] http://apt.myserver.ru/ubuntu/ xenial main restricted universe
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;С настройкой &lt;code&gt;apt-mirror&lt;/code&gt; закончили, перейдем к использованию в тестах.&lt;/p&gt;

&lt;h2 id=&#34;переключение-docker-контейнера-на-локальный-apt-репозиторий&#34;&gt;Переключение Docker контейнера на локальный apt репозиторий&lt;/h2&gt;

&lt;p&gt;&lt;a href=&#34;https://github.com/ekino/docker-images/tree/master/apt-mirror&#34; target=&#34;_blank&#34;&gt;https://github.com/ekino/docker-images/tree/master/apt-mirror&lt;/a&gt; - здесь приведено 2 способа настройки репозитория в контейнере, не изменяя его:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;[Плохой способ] Подмена через DNS&lt;/li&gt;
&lt;li&gt;[Хороший способ] Подмена &lt;code&gt;/etc/apt/sources.list&lt;/code&gt;&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Я выбрал хороший. Делается это монтированием файла на место &lt;code&gt;/etc/apt/sources.list&lt;/code&gt;:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #268BD2&#34;&gt;FQDN&lt;/span&gt;&lt;span style=&#34;color: #719e07&#34;&gt;=&lt;/span&gt;&lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;apt.myserver.ru&amp;quot;&lt;/span&gt;
cat &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;lt;&amp;lt;EOF &amp;gt; sources.list-$FQDN&lt;/span&gt;
&lt;span style=&#34;color: #2AA198&#34;&gt;deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial main restricted universe&lt;/span&gt;
&lt;span style=&#34;color: #2AA198&#34;&gt;deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial-updates main restricted universe&lt;/span&gt;
&lt;span style=&#34;color: #2AA198&#34;&gt;deb [ arch=amd64 ] http://$FQDN/ubuntu/ xenial-security main restricted universe&lt;/span&gt;
&lt;span style=&#34;color: #2AA198&#34;&gt;EOF&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Чтобы не тащить с собой артефакты, файл создается командой.&lt;/p&gt;

&lt;p&gt;После этого проверяем, это должно отработать нормально:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;docker run --rm -it -v &lt;span style=&#34;color: #719e07&#34;&gt;$(&lt;/span&gt;readlink -f sources.list-&lt;span style=&#34;color: #268BD2&#34;&gt;$FQDN&lt;/span&gt;&lt;span style=&#34;color: #719e07&#34;&gt;)&lt;/span&gt;:/etc/apt/sources.list ubuntu:16.04 apt-get update
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Если &lt;code&gt;readlink&lt;/code&gt; выдает ошибку &lt;code&gt;readlink: illegal option -- f&lt;/code&gt;, тогда вы скорее всего сидите на MacOS и вам нужно сделать &lt;code&gt;brew install coreutils&lt;/code&gt; и прописать в переменную &lt;code&gt;PATH&lt;/code&gt; то, что он просит.&lt;/p&gt;

&lt;h2 id=&#34;сравнение-скорости&#34;&gt;Сравнение скорости&lt;/h2&gt;

&lt;p&gt;Я потратил около 4 часов на то, чтобы настроить локальные репозитории, посмотрим, сколько я сэкономил времени.
Скорость инета у меня 30 мбит.&lt;/p&gt;

&lt;p&gt;Я сравнил отработку &lt;code&gt;time molecule test&lt;/code&gt; на 3 ansible ролях, вот результаты:&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Роль&lt;/th&gt;
&lt;th&gt;Стандартный репозиторий&lt;/th&gt;
&lt;th&gt;Локальный репозиторий&lt;/th&gt;
&lt;th&gt;Travis CI:&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ansible-role-common&lt;/td&gt;
&lt;td&gt;8:04&lt;/td&gt;
&lt;td&gt;6:18&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;4:32&lt;/strong&gt;&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-mysql&lt;/td&gt;
&lt;td&gt;3:41&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;3:22&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;3:46&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-zsh&lt;/td&gt;
&lt;td&gt;3:29&lt;/td&gt;
&lt;td&gt;&lt;strong&gt;2:54&lt;/strong&gt;&lt;/td&gt;
&lt;td&gt;4:08&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;p&gt;Как видно, прирост небольшой, всего 20-30%.
UPD 26.02.2017: на при написании &lt;a href=&#34;http://blog.popstas.ru/blog/2017/02/26/apt-cacher-ng-for-testing-ansible-roles-with-docker-and-gitlab-ci/&#34;&gt;статьи про apt-cacher-ng&lt;/a&gt; я перепроверил результаты и разница сократилась до 10-20%.&lt;/p&gt;

&lt;p&gt;Тут надо заметить, что в &lt;code&gt;test&lt;/code&gt; входит проверка идемпотентности, где никакие пакеты не ставятся. Тогда я сравнил время выполнения &amp;lsquo;molecule converge&amp;rsquo; для &lt;code&gt;ansible-role-mysql&lt;/code&gt; и получил немного лучшие результаты: 2:30 против 3:17, это уже почти в 2 раза быстрее.&lt;/p&gt;

&lt;table&gt;
&lt;thead&gt;
&lt;tr&gt;
&lt;th&gt;Роль&lt;/th&gt;
&lt;th&gt;Стандартный репозиторий&lt;/th&gt;
&lt;th&gt;Локальный репозиторий&lt;/th&gt;
&lt;/tr&gt;
&lt;/thead&gt;

&lt;tbody&gt;
&lt;tr&gt;
&lt;td&gt;ansible-role-common&lt;/td&gt;
&lt;td&gt;8:15&lt;/td&gt;
&lt;td&gt;6:09&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-mysql&lt;/td&gt;
&lt;td&gt;3:17&lt;/td&gt;
&lt;td&gt;2:30&lt;/td&gt;
&lt;/tr&gt;

&lt;tr&gt;
&lt;td&gt;ansible-role-zsh&lt;/td&gt;
&lt;td&gt;4:05&lt;/td&gt;
&lt;td&gt;2:43&lt;/td&gt;
&lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

&lt;h2 id=&#34;выводы-по-поводу-apt-mirror&#34;&gt;Выводы по поводу apt-mirror&lt;/h2&gt;

&lt;p&gt;Результаты меня немного расстроили. Оказалось, что поразительного прироста в скорости, на который я надеялся, не будет.&lt;/p&gt;

&lt;h3 id=&#34;плюсы&#34;&gt;Плюсы:&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;один раз потратил время, чтобы при каждом тесте ждать меньше&lt;/li&gt;
&lt;li&gt;уменьшает желание тестировать не на чистой машине&lt;/li&gt;
&lt;li&gt;интернет-канал не занимается в рабочее время&lt;/li&gt;
&lt;/ul&gt;

&lt;h3 id=&#34;минусы&#34;&gt;Минусы&lt;/h3&gt;

&lt;ul&gt;
&lt;li&gt;эффект слабый, 20-30%&lt;/li&gt;
&lt;li&gt;сложности с пробросом файла &lt;code&gt;sources.list&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;уход от стандартной конфигурации Gitlab CI&lt;/li&gt;
&lt;li&gt;разные конфиги для Travis CI и Gitlab CI&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;На основе этого сделал для себя вывод: это подходит только для локального постоянного применения, в остальных случаях минусы перевешивают.&lt;/p&gt;

&lt;h2 id=&#34;что-то-тут-не-так&#34;&gt;Что-то тут не так&amp;hellip;&lt;/h2&gt;

&lt;p&gt;После этого я задумался: а как делают &amp;ldquo;большие&amp;rdquo;? Из серьезных решений для локальных репозиториев я знаю только Artifactory. Пошел посмотреть, как у них обстоят дела с зеркалами и &lt;a href=&#34;https://www.jfrog.com/knowledge-base/how-to-mirror-a-remote-repository/&#34; target=&#34;_blank&#34;&gt;нашел&lt;/a&gt;: они умеют быть зеркалом, но не рекоменуют их так использовать, т.к. это неэффективно. Вместо этого они предлагают пользоваться ими как кеширующим сервером. Такие дела&amp;hellip;&lt;/p&gt;

&lt;p&gt;UPD 26.02.2017: перешел на использование apt-cacher-ng, в моем случае он лучше по всем параметрам, подробности читайте в продолжении&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Docker в картинках</title>
      <link>http://blog.popstas.ru/blog/2016/02/26/docker-in-images/</link>
      <pubDate>Fri, 26 Feb 2016 21:29:45 +0000</pubDate>
      
      <guid>http://blog.popstas.ru/blog/2016/02/26/docker-in-images/</guid>
      <description>&lt;p&gt;Оставлю здесь &lt;a href=&#34;http://habrahabr.ru/post/272145/&#34; target=&#34;_blank&#34;&gt;свой пост&lt;/a&gt; с хабра.&lt;/p&gt;

&lt;p&gt;&lt;em&gt;Перевод поста &lt;a href=&#34;http://merrigrove.blogspot.co.uk/2015/10/visualizing-docker-containers-and-images.html&#34; target=&#34;_blank&#34;&gt;Visualizing Docker Containers and Images&lt;/a&gt;, от новичка к новичкам, автор на простых примерах объясняет базовые сущности и процессы в использовании docker.&lt;/em&gt;&lt;/p&gt;

&lt;p&gt;Если вы не знаете, что такое Docker или не понимаете, как он соотносится с виртуальными машинами или с инструментами configuration management, то этот пост может показаться немного сложным.&lt;/p&gt;

&lt;p&gt;Пост предназначен для тех, кто пытается освоить docker cli, понять, чем отличается контейнер и образ. В частности, будет объяснена разница между просто контейнером и запущенным контейнером.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/8ff/349/fb2/8ff349fb23f840589c479d029964b8dc.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;p&gt;В процессе освоения нужно представить себе некоторые лежащие в основе детали, например, слои файловой системы UnionFS. В течение последней пары недель я изучал технологию, я новичок в мире docker, и командная строка docker показалась мне довольно сложной для освоения.&lt;/p&gt;

&lt;p&gt;По-моему, понимание того, как технология работает изнутри - лучший способ быстро освоить новый инструмент и правильно его использовать. Часто новая технология разрабатывает новые модели абстракций и привносит новые термины и метафоры, которые могут быть как будто бы понятны в начале, но без четкого понимания затрудняют последующее использование инструмента.&lt;/p&gt;

&lt;p&gt;Хорошим примером является Git. Я не мог понять Git, пока не понял его базовую модель, включая trees, blobs, commits, tags, tree-ish и прочее. Я думаю, что люди, не понимающие внутренности Git, не могут мастерски использовать этот инструмент.&lt;/p&gt;

&lt;h2 id=&#34;определение-образа-image&#34;&gt;Определение образа (Image)&lt;/h2&gt;

&lt;p&gt;Визуализация образа представлена ниже в двух видах. Образ можно определить как &amp;ldquo;сущность&amp;rdquo; или &amp;ldquo;общий вид&amp;rdquo; (union view) стека слоев только для чтения.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/243/a01/1ed/243a011ed04f455099a4ba64a87736f6.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Слева мы видим стек слоев для чтения. Они показаны только для понимания внутреннего устройства, они доступны вне запущенного контейнера на хост-системе. Важно то, что они доступны только для чтения (иммутабельны), а все изменения происходят в верхнем слое стека. Каждый слой может иметь одного родителя, родитель тоже имеет родителя и т.д. Слой верхнего уровня может быть использован как UnionFS (AUFS в моем случае с docker) и представлен в виде единой read-only файловой системы, в которой отражены все слои. Мы видим эту &amp;ldquo;сущность&amp;rdquo; образа на рисунке справа.&lt;/p&gt;

&lt;p&gt;Если вы захотите посмотреть на эти слои в первозданном виде, вы можете найти их в файловой системе на хост-машине. Они не видны напрямую из запущенного контейнера. На моей хост-машине я могу найти образы в /var/lib/docker/aufs.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# sudo tree -L 1 /var/lib/docker/
/var/lib/docker/
├── aufs
├── containers
├── graph
├── init
├── linkgraph.db
├── repositories-aufs
├── tmp
├── trust
└── volumes

7 directories, 2 files
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;определение-контейнера-container&#34;&gt;Определение контейнера (Container)&lt;/h2&gt;

&lt;p&gt;Контейнер можно назвать &amp;ldquo;сущностью&amp;rdquo; стека слоев с верхним слоем для записи.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/8d3/d29/494/8d3d29494dbf46f79b1be15cea7516c4.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;На изображении выше показано примерно то же самое, что на изображении про образ, кроме того, что верхний слой доступен для записи. Вы могли заметить, что это определение ничего не говорит о том, запущен контейнер или нет и это неспроста. Разделение контейнеров на запущенные и не запущенные устранило путаницу в моем понимании.&lt;/p&gt;

&lt;p&gt;Контейнер определяет лишь слой для записи наверху образа (стека слоев для чтения). Он не запущен.&lt;/p&gt;

&lt;h2 id=&#34;определение-запущенного-контейнера&#34;&gt;Определение запущенного контейнера&lt;/h2&gt;

&lt;p&gt;Запущенный контейнер - это &amp;ldquo;общий вид&amp;rdquo; контейнера для чтения-записи и его изолированного пространства процессов. Ниже изображен контейнер в своем пространстве процессов.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/c72/5d3/b0b/c725d3b0be5742aca5f50310d640d0b1.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Изоляция файловой системы обеспечивается технологиями уровня ядра, cgroups, namespaces и другие, позволяют докеру быть такой перспективной технологией. Процессы в пространстве контейнера могут изменять, удалять или создавать файлы, которые сохраняются в верхнем слое для записи. Смотрите изображение:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/f8e/bbf/e3b/f8ebbfe3b59346ee9cdb017b89fcb169.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Чтобы проверить это, выполните команду на хост-машине:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run ubuntu touch happiness.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Вы можете найти новый файл в слое для записи на хост-машине, даже если контейнер не запущен.&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;# find / -name happiness.txt
/var/lib/docker/aufs/diff/860a7b...889/happiness.txt
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;определение-слоя-образа-image-layer&#34;&gt;Определение слоя образа (Image layer)&lt;/h2&gt;

&lt;p&gt;Наконец, мы определим слой образа. Изображение ниже представляет слой образа и дает нам понять, что слой - это не просто изменения в файловой системе.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/928/23a/1a0/92823a1a03ad487586293f37e78cf74f.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Метаданные - дополнительная информация о слое, которая позволяет докеру сохранять информацию во время выполнения и во время сборки. Оба вида слоев (для чтения и для записи) содержат метаданные.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/b7e/d04/252/b7ed042525f647b986009b82d18b3fee.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Кроме того, как мы уже упоминали раньше, каждый слой содержит указатель на родителя, используя id (на изображении родительские слои внизу). Если слой не указывает на родительский слой, значит он наверху стека.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/7e9/de2/c4f/7e9de2c4f537438c8f5357d09c398289.png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;расположение-метаданных&#34;&gt;Расположение метаданных&lt;/h3&gt;

&lt;p&gt;На данный момент (я понимаю, что разработчики docker могут позже сменить реализацию), метаданные слоев образов (для чтения) находятся в файле с именем &amp;ldquo;json&amp;rdquo; в папке /var/lib/docker/graph/id_слоя:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;/var/lib/docker/graph/e809f156dc985.../json
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;где &amp;ldquo;e809f156dc985&amp;hellip;&amp;rdquo; - урезанный id слоя.&lt;/p&gt;

&lt;h2 id=&#34;свяжем-все-вместе&#34;&gt;Свяжем все вместе&lt;/h2&gt;

&lt;p&gt;Теперь, давайте посмотрим на команды, иллюстрированные понятными картинками.&lt;/p&gt;

&lt;h3 id=&#34;docker-create-image-id&#34;&gt;docker create &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker create&lt;/code&gt; добавляет слой для записи наверх стека слоев, найденного по &lt;image-id&gt;. Команда не запускает контейнер.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/12c/8d5/606/12c8d56068c5416e8ca003b532ef3cdb.png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-start-container-id&#34;&gt;docker start &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker start&lt;/code&gt; создает пространство процессов вокруг слоев контейнера. Может быть только одно пространство процессов на один контейнер.&lt;/p&gt;

&lt;h3 id=&#34;docker-run-image-id&#34;&gt;docker run &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/730/6c4/4cd/7306c44cdfdd4ead9f1f073d91dd312c.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Один из первых вопросов, который задают люди (я тоже задавал): &amp;ldquo;В чем разница между &lt;code&gt;docker start&lt;/code&gt; и &lt;code&gt;docker run&lt;/code&gt;?&amp;rdquo; Одна из первоначальных целей этого поста - объяснить эту тонкость.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/429/f39/fc6/429f39fc67d44579a40365018dc6839e.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Как мы видим, команда &lt;code&gt;docker run&lt;/code&gt; находит образ, создает контейнер поверх него и запускает контейнер. Это сделано для удобства и скрывает детали двух команд.&lt;/p&gt;

&lt;p&gt;Продолжая сравнение с освоением Git, я скажу, что &lt;code&gt;docker run&lt;/code&gt; очень похожа на &lt;code&gt;git pull&lt;/code&gt;. Так же, как и &lt;code&gt;git pull&lt;/code&gt; (который объединяет &lt;code&gt;git fetch&lt;/code&gt; и &lt;code&gt;git merge&lt;/code&gt;), команда &lt;code&gt;docker run&lt;/code&gt; объединяет две команды, которые могут использоваться и независимо. Это удобно, но поначалу может ввести в заблуждение.&lt;/p&gt;

&lt;h3 id=&#34;docker-ps&#34;&gt;docker ps&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/441/0ed/8b7/4410ed8b7bb94de68dfae60a79a08aca.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker ps&lt;/code&gt; выводит список запущенных контейнеров на вашей хост-машине. Важно понимать, что в этот список входят только запущенные контейнеры, не запущенные контейнеры скрыты. Чтобы посмотреть список всех контейнеров, нужно использовать следующую команду.&lt;/p&gt;

&lt;h3 id=&#34;docker-ps-a&#34;&gt;docker ps -a&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/633/55a/c1a/63355ac1a27d4cf6a1f10142cc89d7b0.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker ps -a&lt;/code&gt;, где &lt;code&gt;a&lt;/code&gt; - сокращение от &lt;code&gt;all&lt;/code&gt; выводит список всех контейнеров, независимо от их состояния.&lt;/p&gt;

&lt;h3 id=&#34;docker-images&#34;&gt;docker images&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/2d2/29e/bc6/2d229ebc667244b3b478298aa3162c7e.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker images&lt;/code&gt; выводит список образов верхнего уровня (top-level images). Фактически, ничего особенного не отличает образ от слоя для чтения. Только те образы, которые имеют присоединенные контейнеры или те, что были получены с помощью pull, считаются образами верхнего уровня. Это различие нужно для удобства, так как за каждым образом верхнего уровня может быть множество слоев.&lt;/p&gt;

&lt;h3 id=&#34;docker-images-a&#34;&gt;docker images -a&lt;/h3&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/5b6/6a9/fd9/5b66a9fd93ce4157b3cfa48984a5ca0d.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker images -a&lt;/code&gt; выводит все образы на хост-машине. Это фактически список всех слоев для чтения в системе. Если вы хотите увидеть все слои одного образа, воспользуйтесь командой &lt;code&gt;docker history&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;docker-stop-container-id&#34;&gt;docker stop &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/f34/430/e32/f34430e3231842e3b748d337993e9338.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker stop&lt;/code&gt; посылает сигнал SIGTERM запущенному контейнеру, что мягко останавливает все процессы в пространстве процессов контейнера. В результате мы получаем не запущенный контейнер.&lt;/p&gt;

&lt;h3 id=&#34;docker-kill-container-id&#34;&gt;docker kill &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/ef8/c77/3c3/ef8c773c34454292b76f798482e15463.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/bdc/1cc/f14/bdc1ccf14b1c4702afe71cbd27a1574b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker kill&lt;/code&gt; посылает сигнал SIGKILL, что немедленно завершает все процессы в текущем контейнере. Это почти то же самое, что нажать Ctrl+\ в терминале.&lt;/p&gt;

&lt;h3 id=&#34;docker-pause-container-id&#34;&gt;docker pause &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/63d/de7/ed4/63dde7ed482544e0afcc2925eabc1e3d.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/70d/208/439/70d208439a1944739c5e06e716ab1975.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;В отличие от &lt;code&gt;docker stop&lt;/code&gt; и &lt;code&gt;docker kill&lt;/code&gt;, которые посылают настоящие UNIX сигналы процессам контейнера, команда &lt;code&gt;docker pause&lt;/code&gt; используют специальную возможность cgroups для заморозки запущенного пространства процессов. Подробности можно прочитать &lt;a href=&#34;https://www.kernel.org/doc/Documentation/cgroups/freezer-subsystem.txt&#34; target=&#34;_blank&#34;&gt;здесь&lt;/a&gt;, если вкратце, отправки сигнала Ctrl+Z (SIGTSTP) не достаточно, чтобы заморозить все процессы в пространстве контейнера.&lt;/p&gt;

&lt;h3 id=&#34;docker-rm-container-id&#34;&gt;docker rm &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/92d/14d/d92/92d14dd9224043079a90ab80c4dbc6a6.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/a36/292/8c4/a362928c4661422797d267560ff38182.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker rm&lt;/code&gt; удаляет слой для записи, который определяет контейнер на хост-системе. Должна быть запущена на остановленном контейнерах. Удаляет файлы.&lt;/p&gt;

&lt;h3 id=&#34;docker-rmi-image-id&#34;&gt;docker rmi &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/4c2/eb5/26a/4c2eb526a35e4751a5302c954370a0fa.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/3a2/145/38a/3a214538a6e54e009f704825109393a1.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker rmi&lt;/code&gt; удаляет слой для чтения, который определяет &amp;ldquo;сущность&amp;rdquo; образа. Она удаляет образ с хост-системы, но образ все еще может быть получен из репозитория через &lt;code&gt;docker pull&lt;/code&gt;. Вы можете использовать &lt;code&gt;docker rmi&lt;/code&gt; только для слоев верхнего уровня (или образов), для удаления промежуточных слоев нужно использовать &lt;code&gt;docker rmi -f&lt;/code&gt;.&lt;/p&gt;

&lt;h3 id=&#34;docker-commit-container-id&#34;&gt;docker commit &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png&#34; /&gt; или &lt;img src=&#34;https://habrastorage.org/files/325/e8e/270/325e8e27098e4cdeb956634361879388.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/daa/69c/50f/daa69c50fbc3479ba9d6497983b73a02.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker commit&lt;/code&gt; берет верхний уровень контейнера, тот, что для записи и превращает его в слой для чтения. Это фактически превращает контейнер (вне зависимости от того, запущен ли он) в неизменяемый образ.&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/e3d/7d7/766/e3d7d7766165425a9148ac61369ffe9c.png&#34; /&gt;&lt;/p&gt;

&lt;h3 id=&#34;docker-build&#34;&gt;docker build&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;Dockerfile &lt;img src=&#34;https://habrastorage.org/files/847/71b/87a/84771b87a8cd4d77b63d39a3ae9dae13.png&#34; /&gt; и &lt;img src=&#34;https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/71a/d30/a1e/71ad30a1e0b04cb09db3e25c741ef7a8.png&#34; /&gt;
Со многими другими слоями.&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker build&lt;/code&gt; интересна тем, что запускает целый ряд команд:
&lt;img src=&#34;https://habrastorage.org/files/b25/36e/cac/b2536ecac84148ba9a043bb00fe3ce5a.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;На изображении выше мы видим, как команда build использует значение инструкции FROM из файла Dockerfile как базовый образ после чего:&lt;/p&gt;

&lt;p&gt;1) запускает контейнер (create и start)
2) изменяет слой для записи
3) делает commit
На каждой итерации создается новый слой. При исполнении &lt;code&gt;docker build&lt;/code&gt; может создаваться множество слоев.&lt;/p&gt;

&lt;h3 id=&#34;docker-exec-running-container-id&#34;&gt;docker exec &lt;running-container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/7d0/ec4/104/7d0ec41049b34238bb785e28897e28f0.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/4d6/cd5/21e/4d6cd521ee4d47e68d89e9ce77c8a6ca.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker exec&lt;/code&gt; применяется к запущенному контейнеру, запускает новый процесс внутри пространства процессов контейнера.&lt;/p&gt;

&lt;h3 id=&#34;docker-inspect-container-id-image-id&#34;&gt;docker inspect &lt;container-id&gt; | &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/74c/7ee/e53/74c7eee53b8f4ed8a2a606e87571fe3a.png&#34; /&gt; или &lt;img src=&#34;https://habrastorage.org/files/242/b58/b68/242b58b68acd4580b226569d81d613e5.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/898/5e8/e54/8985e8e5467a42769988a4351d0c0828.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker inspect&lt;/code&gt; получает метаданные верхнего слоя контейнера или образа.&lt;/p&gt;

&lt;h3 id=&#34;docker-save-image-id&#34;&gt;docker save &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/f2a/b8d/70d/f2ab8d70de7a4ca4959f6a7bf1fb11e3.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/d5d/bf7/3f0/d5dbf73f0f2d4d72b0ed38309e2c6a6b.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker save&lt;/code&gt; создает один файл, который может быть использован для импорта образа на другую хост-систему. В отличие от команды &lt;code&gt;export&lt;/code&gt;, она сохраняет все слои и их метаданные. Может быть применена только к образам.&lt;/p&gt;

&lt;h3 id=&#34;docker-export-container-id&#34;&gt;docker export &lt;container-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/a7f/3f4/717/a7f3f47170084dc2b75dd73e8d6a5cbb.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/36d/807/ed6/36d807ed6b304333b31f658dfb5c4326.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker export&lt;/code&gt; создает tar архив с содержимым файлов контейнера, в результате получается папка, пригодная для использования вне docker. Команда убирает слои и их метаданные. Может быть применена только для контейнеров.&lt;/p&gt;

&lt;h3 id=&#34;docker-history-image-id&#34;&gt;docker history &lt;image-id&gt;&lt;/h3&gt;

&lt;p&gt;До:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/428/150/afc/428150afc2574fd2bf32f1202c908f77.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;После:&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://habrastorage.org/files/e82/45f/511/e8245f51120340b19e07c6009f2d4ce8.png&#34; /&gt;&lt;/p&gt;

&lt;p&gt;Команда &lt;code&gt;docker history&lt;/code&gt; принимает &lt;image-id&gt; и рекурсивно выводит список всех слоев-родителей образа (которые тоже могут быть образами)&lt;/p&gt;

&lt;h2 id=&#34;итог&#34;&gt;Итог&lt;/h2&gt;

&lt;p&gt;Я надеюсь, вам понравилась эта визуализация контейнеров и образов. Есть много других команд (pull, search, restart, attach и другие), которые могут или не могут быть объяснены моими сравнениями.&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Автоматическое скачивание торрентов с Weburg в Transmission и статистика на InfluxDB &amp; Grafana</title>
      <link>http://blog.popstas.ru/blog/2016/01/17/torrent-transmission-client-for-weburg/</link>
      <pubDate>Sun, 17 Jan 2016 08:22:25 +0000</pubDate>
      
      <guid>http://blog.popstas.ru/blog/2016/01/17/torrent-transmission-client-for-weburg/</guid>
      <description>&lt;p&gt;У моего интернет-провайдера Планета есть бонусная программа поощрения раздачи торрентов с &lt;a href=&#34;http://weburg.net&#34; target=&#34;_blank&#34;&gt;weburg.net&lt;/a&gt;, дающая бонусы,
их можно тратить на абонентскую плату. У меня комп постоянно включен, я сразу стал участвовать.&lt;/p&gt;

&lt;p&gt;Поддержку раздач можно разбить на несколько задач:&lt;/p&gt;

&lt;ol&gt;
&lt;li&gt;периодически скачивать новинки фильмов&lt;/li&gt;
&lt;li&gt;скачивать новые серии популярных сериалов&lt;/li&gt;
&lt;li&gt;удалять то, что плохо раздается&lt;/li&gt;
&lt;/ol&gt;

&lt;p&gt;Через пару месяцев мне это надоело, задумался об автоматизации этого процесса и вот в новогодние каникулы родился
&lt;a href=&#34;https://github.com/popstas/transmission-cli&#34; target=&#34;_blank&#34;&gt;transmission-cli&lt;/a&gt; - консольная утилита, решающая часть этих задач.&lt;/p&gt;

&lt;p&gt;&lt;iframe src=&#34;https://ghbtns.com/github-btn.html?user=popstas&amp;repo=transmission-cli&amp;type=star&amp;count=true&amp;size=large&#34; frameborder=&#34;0&#34; scrolling=&#34;0&#34; width=&#34;160px&#34; height=&#34;30px&#34;&gt;&lt;/iframe&gt;
&lt;a href=&#34;https://travis-ci.org/popstas/transmission-cli&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://travis-ci.org/popstas/transmission-cli.svg?branch=master&#34; alt=&#34;Build Status&#34; /&gt;&lt;/a&gt;
&lt;a href=&#34;https://coveralls.io/github/popstas/transmission-cli?branch=master&#34; target=&#34;_blank&#34;&gt;&lt;img src=&#34;https://coveralls.io/repos/popstas/transmission-cli/badge.svg?branch=master&amp;amp;service=github&#34; alt=&#34;Coverage Status&#34; /&gt;&lt;/a&gt;&lt;/p&gt;

&lt;p&gt;&lt;img src=&#34;https://github.com/popstas/transmission-cli/raw/master/docs/img/grafana.png?raw=true&#34; /&gt;&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;

&lt;h2 id=&#34;возможности&#34;&gt;Возможности&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;скачивание популярных торрентов с &lt;a href=&#34;http://weburg.net&#34; target=&#34;_blank&#34;&gt;http://weburg.net&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;удаление дублирующихся раздач (для сериалов)&lt;/li&gt;
&lt;li&gt;отправка метрик в InfluxDB (для слежения за популярностью)&lt;/li&gt;
&lt;/ul&gt;

&lt;h1 id=&#34;установка&#34;&gt;Установка&lt;/h1&gt;

&lt;p&gt;Установить клиент можно так:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #268BD2&#34;&gt;latest_phar&lt;/span&gt;&lt;span style=&#34;color: #719e07&#34;&gt;=$(&lt;/span&gt;curl -s https://api.github.com/repos/popstas/transmission-cli/releases/latest &lt;span style=&#34;color: #93A1A1&#34;&gt;|&lt;/span&gt; grep &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;#39;browser_&amp;#39;&lt;/span&gt; &lt;span style=&#34;color: #93A1A1&#34;&gt;|&lt;/span&gt; cut -d&lt;span style=&#34;color: #CB4B16&#34;&gt;\&amp;quot;&lt;/span&gt; -f4&lt;span style=&#34;color: #719e07&#34;&gt;)&lt;/span&gt;
wget -O /usr/local/bin/transmission-cli &lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #268BD2&#34;&gt;$latest_phar&lt;/span&gt;&lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;&lt;/span&gt;
chmod +x /usr/local/bin/transmission-cli
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Пользоваться графиками можно с трудом, потому что InfluxDB и Grafana вам придется устанавливать самостоятельно.
Я ставил то и другое в docker на свою виртуалку и пробрасывал порты на localhost,
сейчас localhost вшит в &lt;a href=&#34;https://github.com/popstas/transmission-cli/blob/master/src/Config.php&#34; target=&#34;_blank&#34;&gt;конфиг&lt;/a&gt;,
который по сути сейчас находится в коде.&lt;/p&gt;

&lt;p&gt;Поставить можно так, заменив папки &lt;code&gt;/Users/popstas/lib/grafana&lt;/code&gt; и &lt;code&gt;/var/lib/influxdb&lt;/code&gt; на ваши,
это укажет, где будут храниться данные InfluxDB и Grafana:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;docker run -d \ -p 3000:3000 \
           -v /Users/popstas/lib/grafana:/var/lib/grafana \
            --name grafana grafana/grafana

docker run -d -p 8083:8083 -p 8086:8086 \
           -v /var/lib/influxdb:/data \
           --name influxdb tutum/influxdb
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Папку от InfluxDB я оставил в виртуалке, т.к. оказалось, что InfluxDB не может работать с папкой, смонтированной в
VirtualBox из Mac OS (какой-то старый глюк docker).&lt;/p&gt;

&lt;p&gt;Чтобы собиралась статистика, нужно добавить в cron задания, я собираю с 2 компов, поэтому добавляю 2 раза.&lt;/p&gt;

&lt;p&gt;Также, чтобы не было конфликтов, статистика не будет отсылаться, если найдет раздачи с одинаковыми названиями,
которые обычно остаются от сериалов. Поэтому их нужно чистить перед отпправкой статистики.&lt;/p&gt;

&lt;p&gt;Раздачи у меня скачиваются в папку, за которой следят оба Transmission, как только туда попадает торрент, раздача
сразу начинается (можно сделать, чтобы спрашивала разрешение, настраивается в Transmission).&lt;/p&gt;

&lt;p&gt;В итоге у меня получился такой cron:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;PATH=&amp;quot;$PATH:/usr/local/bin&amp;quot;
59 * * * * transmission-cli remove-duplicates --host=localhost
59 * * * * transmission-cli remove-duplicates --host=wrtnsq
0  * * * * transmission-cli send-metrics --host=localhost
0  * * * * transmission-cli send-metrics --host=wrtnsq
1  2 * * * transmission-cli download-weburg --dest=/Volumes/media/_planeta/_torrents
&lt;/code&gt;&lt;/pre&gt;

&lt;h2 id=&#34;результаты-статистики&#34;&gt;Результаты статистики&lt;/h2&gt;

&lt;p&gt;Никогда не знал о своих раздачах ничего, кроме рейтинга и объема розданного за все время.
Графики показали интересные вещи (о которых можно было и так догадаться):&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;с 18 до 22 пик раздач, с 22 до 2 спад, с 2 до 9 все спят&lt;/li&gt;
&lt;li&gt;в праздники и выходные больше качают днем и до ночи, но после 2 все равно все спят&lt;/li&gt;
&lt;li&gt;популярные фильмы популярны обычно не больше недели&lt;/li&gt;
&lt;li&gt;есть популярные фильмы, которые популярны и через несколько месяцев, например &amp;ldquo;Интерстеллар&amp;rdquo;&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Сейчас я могу выбрать в Grafana период в 7 дней, отсортировать раздачи по розданным Гб и получить список
раздач-кандидатов на удаление.&lt;/p&gt;

&lt;p&gt;Со статистикой еще надо работать, что еще хочется сделать:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;&lt;p&gt;нормальную группировку по периодам, сейчас группируется только за час или за весь выбранный период,
нельзя выбрать последнюю неделю и посмотреть посуточные метрики. Я скидываю метрики и сначала не понимал,
почему так, но тут как раз вышла статья
&lt;a href=&#34;http://habrahabr.ru/post/274303/&#34; target=&#34;_blank&#34;&gt;Почему расчет перцентилей работает не так как вы ожидаете?&lt;/a&gt; и многое мне объяснила.&lt;/p&gt;&lt;/li&gt;

&lt;li&gt;&lt;p&gt;добавить в метрики инфу о весе раздач и вывести эффективность раздач: например, фильм в 1080p весом в 10 Гб
скачали на 50 Гб за неделю, а 2 Гб фильм низкого качества скачали на 10 Гб, если не учитывать вес раздач, то выходит,
что первая раздача в 5 раз эффективнее, но если учитвать, то оказвается, что они равны.&lt;/p&gt;&lt;/li&gt;
&lt;/ul&gt;

&lt;h2 id=&#34;техническая-часть&#34;&gt;Техническая часть:&lt;/h2&gt;

&lt;ul&gt;
&lt;li&gt;Symfony console - каркас консольной утилиты&lt;/li&gt;
&lt;li&gt;InfluxDB - хранилище метрик&lt;/li&gt;
&lt;li&gt;Grafana - рисование графиков&lt;/li&gt;
&lt;li&gt;Composer - управление зависимостями&lt;/li&gt;
&lt;li&gt;Box - &lt;a href=&#34;http://habrahabr.ru/post/274745/&#34; target=&#34;_blank&#34;&gt;сборка PHAR&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;PHPCS, PHPMD - линтеры PHP&lt;/li&gt;
&lt;li&gt;Travis CI - публицация PHAR на Github&lt;/li&gt;
&lt;li&gt;Coveralls - сервис слежения за покрытием кода тестами&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Половину из этого я ни разу не использовал, вторую половину - немного. Поэтому граблей хватает.&lt;/p&gt;

&lt;h3 id=&#34;symfony-console&#34;&gt;Symfony console&lt;/h3&gt;

&lt;p&gt;Тут мне сказать особо нечего, фреймворки я только начинаю осваивать, пока ничего не понятно с Dependency Injection,
чувствую, что у меня переменные в функции местами прокидываются криво, а местами не прокидываются, где стоило бы.&lt;/p&gt;

&lt;p&gt;Не понятно, как тестить через PHPUnit, как мокать объекты.&lt;/p&gt;

&lt;p&gt;Пока радуюсь, что освоился с namespaces и использовал на практике PSR-2 и PSR-4.&lt;/p&gt;

&lt;p&gt;Почти все идеи взяты из исходников
&lt;a href=&#34;https://github.com/composer/composer&#34; target=&#34;_blank&#34;&gt;composer&lt;/a&gt; и
&lt;a href=&#34;https://github.com/MartialGeek/transmission-api&#34; target=&#34;_blank&#34;&gt;transmission-api&lt;/a&gt;&lt;/p&gt;

&lt;h3 id=&#34;influxdb&#34;&gt;InfluxDB&lt;/h3&gt;

&lt;p&gt;InfluxDB не может работать с папкой, смонтированной в VirtualBox из Mac OS (какой-то старый глюк docker).&lt;/p&gt;

&lt;p&gt;InfluxDB я раньше не видел, хотел посмотреть ее как замену для хранилища Whisper из стека
Diamond -&amp;gt; Carbon -&amp;gt; Whisper -&amp;gt; Graphite -&amp;gt; Grafana для рисования графиков сервера.&lt;/p&gt;

&lt;p&gt;Компания, стоящая за InfluxDB с недавнего времени назвается InfluxData и предлагает свой стек
&lt;a href=&#34;https://influxdata.com/time-series-platform/&#34; target=&#34;_blank&#34;&gt;TICK&lt;/a&gt;, в который
входит еще и алертинг по отклонениям метрик. Могу сказать о нем то, что Telegraf работает, InfluxDB работает без тормозов,
собирая с моего компа метрики раз в 10 секунд, Chronograf какой-то неполноценный, по сравнению с Grafana,
а Kapacitor я еще не смотрел (UPD 19.05.2016: &lt;a href=&#34;http://blog.popstas.ru/blog/categories/kapacitor/&#34;&gt;уже смотрел&lt;/a&gt;).&lt;/p&gt;

&lt;h3 id=&#34;grafana&#34;&gt;Grafana&lt;/h3&gt;

&lt;p&gt;В Grafana 2.6 появилось много нового, по сравнению с 2.0, которую я видел в августе. А вообще, если кто использовал
Cacti или Graphite и не видел Grafana, посмотрите, красота неописуемая.&lt;/p&gt;

&lt;h3 id=&#34;composer&#34;&gt;Composer&lt;/h3&gt;

&lt;p&gt;Некоторые dev-пакеты (phpunit) потребовали php 5.6 для запуска, поэтому поставил 5.6 минимальной необходимой версией,
хотя по факту клиент может работать и на 5.5, а на 5.4 уже не может.&lt;/p&gt;

&lt;h3 id=&#34;box&#34;&gt;Box&lt;/h3&gt;

&lt;p&gt;Если собирать PHAR, используя box, установленный через composer, в архив попадает много ненужных dev-пакетов.
Сначала я пытался бороться с этим исключением пакетов через box.json, потом понял, что это бесполезно
(все пакеты не исключишь, а однажды исключишь нужный), в итоге пришел к такой схеме:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ставим пакеты через &lt;code&gt;composer install --no-dev&lt;/code&gt;&lt;/li&gt;
&lt;li&gt;качаем box.phar&lt;/li&gt;
&lt;li&gt;собираем transmission-cli.phar&lt;/li&gt;
&lt;li&gt;доставляем пакеты через composer update&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Это в 3 раза уменьшило вес собранного архива.&lt;/p&gt;

&lt;h3 id=&#34;phpcs-phpmd&#34;&gt;PHPCS, PHPMD&lt;/h3&gt;

&lt;p&gt;PHP Code Sniffer умеет анализировать ваш код на соответствие определенным стандартам, в моем случае PSR-2,
ставится через Composer, используется так:&lt;/p&gt;

&lt;pre&gt;&lt;code&gt;./vendor/bin/phpcs --standard=psr2 ./src
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;А PHP Mess Detector у меня не запустился.&lt;/p&gt;

&lt;h3 id=&#34;travis-ci&#34;&gt;Travis CI&lt;/h3&gt;

&lt;p&gt;Впервые удалось использовать его по назначению. Как-то пробовал использовать его для тестов пакета bash скриптов
&lt;a href=&#34;https://github.com/popstas/drupal-scripts&#34; target=&#34;_blank&#34;&gt;drupal-scripts&lt;/a&gt;, но быстро сдался, т.к. в окружении travis они вели себя не так,
как на локалке (в итоге перекинул тесты на TeamCity).&lt;/p&gt;

&lt;p&gt;На этом проекте travis прогоняет тесты phpunit
(тестов по сути еще нет, но без phpunit в каком-либо виде travis по умолчанию фейлит сборку)
и если к коммиту был проставлен git tag,
публикует PHAR как приложение к релизу на Github, чуть подробнее я написал
в &lt;a href=&#34;http://habrahabr.ru/post/274745/#comment_8736379&#34; target=&#34;_blank&#34;&gt;этом комменте&lt;/a&gt;.&lt;/p&gt;

&lt;h3 id=&#34;coveralls&#34;&gt;Coveralls&lt;/h3&gt;

&lt;p&gt;До покрытия тестами я еще не добирался, я тесты-то еще только начинаю использовать, решил попробовать на этом проекте.&lt;/p&gt;

&lt;p&gt;Чтобы добавить coveralls в самом простом случае (в доках есть и сложные), достаточно сделать так, чтобы PHPUnit
генерил файл &lt;code&gt;build/logs/clover.xml&lt;/code&gt;, для этого надо добавить строчку в phpunit.xml, в секцию logging:&lt;/p&gt;
&lt;div class=&#34;highlight&#34; style=&#34;background: #002B36&#34;&gt;&lt;pre style=&#34;line-height: 125%&#34;&gt;&lt;span&gt;&lt;/span&gt;&lt;span style=&#34;color: #268BD2&#34;&gt;&amp;lt;logging&amp;gt;&lt;/span&gt;
    &lt;span style=&#34;color: #268BD2&#34;&gt;&amp;lt;log&lt;/span&gt; &lt;span style=&#34;color: #93A1A1&#34;&gt;type=&lt;/span&gt;&lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;coverage-clover&amp;quot;&lt;/span&gt; &lt;span style=&#34;color: #93A1A1&#34;&gt;target=&lt;/span&gt;&lt;span style=&#34;color: #2AA198&#34;&gt;&amp;quot;build/logs/clover.xml&amp;quot;&lt;/span&gt;&lt;span style=&#34;color: #268BD2&#34;&gt;/&amp;gt;&lt;/span&gt;
&lt;span style=&#34;color: #268BD2&#34;&gt;&amp;lt;/logging&amp;gt;&lt;/span&gt;
&lt;/pre&gt;&lt;/div&gt;

&lt;p&gt;Ну и конечно зарегаться на &lt;a href=&#34;https://coveralls.io/&#34; target=&#34;_blank&#34;&gt;https://coveralls.io/&lt;/a&gt; и активировать там проект.
Если путь будет другой, придется читать доки и создавать файл настройки .coveralls.yml&lt;/p&gt;

&lt;p&gt;В результате я имею красивую красную ачивку на странице проекта
и &lt;a href=&#34;https://coveralls.io/github/popstas/transmission-cli&#34; target=&#34;_blank&#34;&gt;историю деградации покрытия&lt;/a&gt; :)&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>
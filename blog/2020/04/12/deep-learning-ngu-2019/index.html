<!doctype html><html xmlns=http://www.w3.org/1999/xhtml xml:lang=en lang=en-us><head><meta charset=utf-8><meta name=viewport content="width=device-width,minimum-scale=1,maximum-scale=1"><link href=/css/fonts.css rel=stylesheet type=text/css><meta property="og:description" content="Курс &ldquo;Deep learning на пальцах - 2019&rdquo; от sim0nsays
Хорошие обзорные теоретические курсы по нейросетям. У них есть недостаток: отсутствие таймкодов.
Этот пост по сути список таймкодов.
На данный момент я посмотрел 10 лекций."><meta property="og:type" content="article"><meta property="og:url" content="https://blog.popstas.ru/blog/2020/04/12/deep-learning-ngu-2019/"><meta property="og:title" content="Конспекты курса Deep Learning на пальцах 2019: таймкоды"><meta property="og:image" content="https://blog.popstas.ru/images/2020-04/deep-learning-2019.jpg"><title>Конспекты курса Deep Learning на пальцах 2019: таймкоды - ML</title><link rel=stylesheet href=/css/hugo-octopress.css><link rel=stylesheet href=https://blog.popstas.ru/css/custom.css><link rel=stylesheet href=/css/fork-awesome.min.css><link href=https://blog.popstas.ru/favicon.png rel=icon><link href=http://feeds.feedburner.com/popstas rel=alternate type=application/rss+xml title=RSS><meta name=description content><meta name=keywords content="ML,tensorflow,pytorch"><meta name=author content="Stanislav Popov"><meta name=generator content="Hugo 0.66.0"></head><body><header role=banner><hgroup><div><a href=https://blog.popstas.ru/>Popstas</a></div><div>Записки о Linux</div></hgroup></header><nav role=navigation><fieldset class=mobile-nav><select onchange="location=this.value;">
<option value>Navigate…</option></select></fieldset><ul class=main-navigation></ul><ul class=subscription><a href=http://feeds.feedburner.com/popstas target=_blank type=application/rss+xml title=RSS><i class="fa fa-rss-square fa-lg"></i></a></ul><form action=https://www.google.com/search method=get target=_blank><fieldset role=search><input class=search type=text name=q results=0 placeholder="Поискать в Google">
<input type=hidden name=q value=site:https://blog.popstas.ru/></fieldset></form></nav><div id=main><div id=content><div><article class=hentry role=article itemscope itemtype=http://schema.org/Article><meta itemprop="author publisher" content="Stanislav Popov"><meta itemprop=mainEntityOfPage content="https://blog.popstas.ru/blog/2020/04/12/deep-learning-ngu-2019/"><header><h1 class=entry-title itemprop=headline>Конспекты курса Deep Learning на пальцах 2019: таймкоды</h1><p class="meta header-date">12.04.2020, 22:51 - 11 мин читать</p></header><div class=entry-content itemprop=articleBody><p><a href="https://www.youtube.com/playlist?list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb">Курс &ldquo;Deep learning на пальцах - 2019&rdquo; от sim0nsays</a></p><p>Хорошие обзорные теоретические курсы по нейросетям. У них есть недостаток: отсутствие таймкодов.</p><p>Этот пост по сути список таймкодов.</p><p>На данный момент я посмотрел 10 лекций.</p><p><img src=/images/2020-04/deep-learning-2019.jpg alt></p><h2 id=1-введениеhttpswwwyoutubecomwatchv_q46x0tq2fqlistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex1><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=1">1. Введение</a></h2><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=8m0s">8:00</a> - определение ИИ. Часто под ИИ подразумеваются задачи, которые человечество только недавно научились решать. Например OCR. Ключевая задача - распознавание: картинок, звука, текста.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=15m52s">15:52</a> - прогресс распознавания картинок и речи с 2011 года. Про разные домены: машинный перевод, поиск, NLP.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=28m35s">28:35</a> - опрелеление ML.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=32m35s">32:35</a> - как работает ML-алгоритм на распознавании рукописных чисел на датасете MNIST.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=37m44s">37:44</a> - описание Deep Learning.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=46m28s">46:28</a> - Computer vision features - SIFT.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=50m55s">50:55</a> - об AlexNet.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=57m18s">57:18</a> - краткое содержание курса и прохождение заданий для студентов.</p><p><a href="https://www.youtube.com/watch?v=_q46x0tq2FQ&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h01m27s">1:01:27</a> - другие онлайн-курсы, книги, сообщества.</p><h2 id=2-элементы-машинного-обученияhttpswwwyoutubecomwatchv1buub28fdoclistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wb><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb">2. Элементы машинного обучения</a></h2><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=4m15s">4:15</a> - supervised learning (обучение с учителем), способ обучения, когда данные размечаются и после этого скармливаются в алгоритм, который выдаст модель - кусок кода, который может делать prediction для подобных новых (не размеченных) данных.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=6m25s">6:25</a> - как распознавать цифры номеров домов из датасета Street View House Numbers.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=10m05s">10:05</a> - метод ближайших соседей Nearest neighbor.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=12m21s">12:21</a> - nearest neighbor выдаст точность предсказаний на тренировочных данных 100%, но это не значит, что модель хорошо будет работать на новых данных.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=15m25s">15:25</a> - это исправляет метод k-ближайших соседей K-nearest neighbors.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=19m58s">19:58</a> - K - это гиперпараметр, то есть подбирается не во время тренировки, а перед этим.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=20m43s">20:43</a> - переобучение и недообучение, overfitting vs underfitting.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=24m58s">24:58</a> - про разделение датасета на train, val и test.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=28m11s">28:11</a> - кросс-валидация, cross-validation, когда весь датасет используется для тренировки, а val-данные каждый раз выбираются разные.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=36m32s">36:32</a> - бинарная классификация, binary classification, когда классов всего 2.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=37m25s">37:25</a> - о несбалансированных датасетов, когда класс A в датасете 99%, а класс B 1%, тогда модель, которая всегда называет класс A даёт точность 99%, борьба дальше идёт за доли процента.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=39m35s">39:35</a> - про precision и recall. Отражает процент false positive и false negative.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=45m34s">45:34</a> - многоклассовая классификация, multi-class classification.</p><p><a href="https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=51m10s">51:10</a> - как определять недообучение и переобучение. Если ошибка на train большая - недообучение. Если ошибка на val большая - переобучение. Ошибка на test показывает реальную точность.</p><h2 id=3-нейронные-сетиhttpswwwyoutubecomwatchvkwtc1nvl894listpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex3><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=3">3. Нейронные сети</a></h2><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=2m44s">2:44</a> - откуда взялась идея нейросетей, как они в общем работают.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=9m41s">9:41</a> - линейный классификатор, linear classifier, система перемножения матриц, эквивалентна простой нейросети.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=14m55s">14:55</a> - разделяющие плоскости в n-мерном пространстве.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=16m11s">16:11</a> - цель всех вычислений: найти лучшие w и b, которые будут лучше всего приближать данные, лучшим образом разделять плоскостями разные классы.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=21m12s">21:12</a> - метод градиентного спуска, gradient descent. Градиент - многомерная производная, которая говорит, в каком направлении надо двигаться, чтобы оптимальнее всего уменьшить или увеличить функцию. В итоге вычислений скатываемся в локальный минимум.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=28m02s">28:02</a> - softmax - функция оптимизации, которая приводит все числа весов (от минус бесконечности до бесконечности) к числам от 0 до 1, которые будут отражать вероятность.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=35m11s">35:11</a> - принцип максимального правдоподобия, maximum likelihood: у модели должны быть такие w и b, которые определяют максимальную сумму вероятностей (чтобы все классы определялись).</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=38m51s">38:51</a> - функция Cross-Entropy loss - функция оптимизации, которая отражает, насколько мала ошибка.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=41m39s">41:39</a> - регуляризация, regularization. Техника, которая усложняет задачу оптимизации, но при этом сковывают её.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=46m17s">46:17</a> - как посчитать градиентный спуск (теория).</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=53m52s">53:52</a> - стохастический (случайный) градиентный спуск, stochastic gradiend descent (SGD). Это когда вместо всего датасета на каждый шаг выбирают случайное кол-во данных и расчёт идёт только по ним.</p><p>Batch size - размер выборки данных для одного прохода, чтобы не перемножать весь датасет (обычно это невозможно).</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h03m41s">1:03:41</a> - слои нейронных сетей.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h04m36s">1:04:36</a> - функция акцивации, non-linear function. ReLu - дефолтный выбор функции активации.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h10m03s">1:10:03</a> - как посчитать градиентный спуск (практика). Обратное распространение ошибки, backpropogation.</p><p><a href="https://www.youtube.com/watch?v=kWTC1NvL894&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h23m00s">1:23:00</a> - общая схема вычисления градиента.</p><h2 id=4-pytorch-и-подробностиhttpswwwyoutubecomwatchvtnrbx7v9rbalistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex4><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=4">4. PyTorch и подробности</a></h2><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=8m23s">8:23</a> - вычисление градиента с матрицами.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=23m13s">23:13</a> - интерфейс слоя, layer interface в PyTorch.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=25m27s">25:27</a> - общая схема тренировки.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=27m56s">27:56</a> - пример решения многоклассовой классификации, multi-class classification.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=29m06s">29:06</a> - multi-class labeling, когда на картинке может быть более одного объекта, softmax не подходит, используется другая функция вероятности sigmoid и loss-функция binary cross-entropy loss.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=33m02s">33:02</a> - regression, нахождение носов, носов и глаз.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=37m48s">37:48</a> - библиотеки для глубокого обучения, описание возможностей, пример на PyTorch.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=51m45s">51:45</a> - подготовка данных, data preprocessing.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=55m47s">55:47</a> - выбор функции активации. rectifier linear unit (ReLU).</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h02m56s">1:02:56</a> - инициализация весов, weight initialization. Xavier initialization. He initialization.</p><p><a href="https://www.youtube.com/watch?v=tnrbx7V9RbA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h10m06s">1:10:06</a> - обновление параметров, update rules. Модификации SGD: Momentum, Adagrad, Adadelta, Rmsprop. Adam - дефолтный выбор градиентного спуска.</p><h2 id=5-нейросети-на-практикеhttpswwwyoutubecomwatchv2gin9cvn9calistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex5><a href="https://www.youtube.com/watch?v=2gIn9cVn9cA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=5">5. Нейросети на практике</a></h2><p><a href="https://www.youtube.com/watch?v=2gIn9cVn9cA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=8m49s">8:49</a> - сравнение процессора и GPU по TFlops</p><p><a href="https://www.youtube.com/watch?v=2gIn9cVn9cA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=18m00s">18:00</a> - последствия ошибок на train, validate, test</p><p>TensorBoard - визуальное отображение loss & accuracy.</p><p>Annealing - гиперпараметр про уменьшение learning rate с течением эпох. В PyTorch это <code>torch.optim.lr_scheduler</code>. Применяется при недообучении (underfitting).</p><p><a href="https://www.youtube.com/watch?v=2gIn9cVn9cA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=27m55s">27:55</a> - про переобучение. Лечится регуляризацией.</p><p>L2 regularization - самое простое.</p><p>Dropout - рандомное убирание частей данных во время или после тренировки. Обычно вставляют в конце сети.</p><p>Batch normalization - слой после весов, делает поток предсказуемого масштаба: среднее 0, std 1 (стандартное отклонение). Убирает выбросы в датасете. Чаще ставят после слоя активации (ReLu). Обычно ставят после каждого слоя весов.</p><p>Если собрать ансамбль моделей, предсказывать всеми и выдавать среднее, то результаты должны быть чуть лучше.</p><p>Learning rate можно подбирать либо линейно, потом смотреть лучший, либо пилой (больше-меньше), это даёт возможность скатившейся в локальный минимум точке выпрыгнуть оттуда и скатиться в более оптимальный минимум. Из разных минимумов можно собрать ансамбль.</p><p><a href="https://www.youtube.com/watch?v=2gIn9cVn9cA&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h17m27s">1:17:27</a> - про инженерный подбор гиперпараметров.</p><p>ONNX - стандарт экспорта моделей.</p><h2 id=6-convolutional-neural-networkshttpswwwyoutubecomwatchvtogbz8lfz8qlistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex6><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=6">6. Convolutional Neural Networks</a></h2><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=14m47s">14:47</a> - паттерны (или фильтры) свёртки для обработки изображений</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=31m15s">31:15</a> - padding и stride. Padding - заполнение (обычно нулями) частей, которые выходят за пределы матрицы. Stride - шаг, с которым скачем по матрице.</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=35m25s">35:25</a> - pooling layer - слой, меняющий разрешение по формуле Max pool (берёт максимум из объединяемых пикселей). При обратном проходе градиент отдаётся максимальному пикселю, остальным отдаёт ноль. Ставится после слоя активации.</p><p>Архитектура CNN с Max pooling хорошо работает со сдвигами изображений.</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=45m30s">45:30</a> - рецептивное поле (receptive field) - то, какого размера поле в исходном изображении влияет на конкретный нейрон.</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=50m15s">50:15</a> - примеры архитектур CNN.</p><p>LeNet&rsquo;98 - сеть для распознавания цифр в почтовых индексах.</p><p>ImageNet - датасет из 1М картин, размечено 1000 классов.</p><p>AlexNet&rsquo;12 - 15.4% ошибок, 16М параметров.</p><p>VGG&rsquo;14 - 6.8% ошибок, 140М параметров.</p><p>ResNet&rsquo;15 - 3.57% ошибок, решение проблемы тренировки сети с большим кол-вом слоёв (> 50). Чтобы один из слоёв не ломал все вычисления, стали передавать вход сразу на выход, а слой может только подправить, <code>f(x)+x</code>. Вход передаётся на выход через 2 слоя + ReLu.</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h07m55s">1:07:55</a> - transfer learning, переобучение чужой сети. Если у нас всего 10-100 картинок, то замораживаются все слои сети, кроме последнего (не тренируются), в последнем меняем классы.</p><p>Если картинок около 1000, то можно заморозить не все слои, а часть, оставшиеся тренировать с разным learning rate, чем глубже, тем медленнее.</p><p><a href="https://www.youtube.com/watch?v=tOgBz8lFz8Q&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h17m40s">1:17:40</a> - аугментация - создание картинок из картинок. Например, можно отразить картинку и увеличить датасет в 2 раза. Потом можно делать смещения, изменения цвета, повороты, наклоны и т.д.
Аугментацию вставляют после выбора минибатча. Есть готовая либа <a href=https://github.com/albumentations-team/albumentations>Albumentations</a>. Встроенные либы тоже есть. Эффект как у ансамбля моделей.</p><h2 id=7-segmentation-и-object-detection-владимир-игловиковhttpswwwyoutubecomwatchvr2ka99theh4listpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex7><a href="https://www.youtube.com/watch?v=r2KA99ThEH4&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=7">7. Segmentation и Object Detection (Владимир Игловиков)</a></h2><p>Сегментация - это попиксельная классификация, когда на выходе получается картинка того же разрешения, но у каждого пикселя есть инфа, к какому классу он относится.</p><p>FCN (fully convolutional network) - сеть без dense слоёв, только из convolution слоёв.</p><p>Dense слои - fully connected слои.</p><p>U-Net - сеть, условно состоящая из 2 частей: encoder (распознаёт картинку, уменьшая разрешение) и decoder (разворачивает распознанную картинку в первоначальное разрешение).</p><p><a href="https://www.youtube.com/watch?v=r2KA99ThEH4&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=42m25s">42:25</a> - FPN (feature pyramid network). Решает проблему масштаба. Делается несколько параллельных слоёв, которые работают с разными размерами картинок.</p><p><a href="https://www.youtube.com/watch?v=r2KA99ThEH4&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=44m50s">44:50</a> - U-Net + FPN. Разные слои (уровни пирамиды) работают с картинками разного разрешения, потом верхние слои с большим разрешением подаются на вход нижнего слоя и на вход следующего слоя.</p><p><a href="https://www.youtube.com/watch?v=r2KA99ThEH4&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=49m55s">49:55</a> - Segmentation loss function. Тут ничего не понял&mldr;</p><p><a href="https://www.youtube.com/watch?v=r2KA99ThEH4&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=56m00s">56:00</a> - вторая часть.</p><p>Детекция - определение габаритов объектов: координаты, класс, аттрибуты.</p><p>Делятся на One-shot и Two-shot, вторые точнее, но дольше.</p><p>One-shot детекторы: YOLO (You only look once) (делит картинку на квадраты, боксы рисует по контурам квадратов, менее точно, но быстрее).</p><p>One-shot detector + FPN = SSD.</p><p>Как я понял, из two-shot надо брать Faster-RCNN.</p><h2 id=8-metric-learning-autoencoders-ganshttpswwwyoutubecomwatchvajeq10s8xrglistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex8><a href="https://www.youtube.com/watch?v=ajEQ10s8XRg&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=8">8. Metric Learning, Autoencoders, GANs</a></h2><p>Embedding - внутреннее представление картинки нейросетью перед классификацией (на предпоследнем слое). Набор внеторов, отражающих все знания сети о картинке.</p><p>По векторам можно сравнивать картинки и находить похожие по заданному признаку, это может быть как поза любого человека, так и один и тот же человек в разных позах.</p><p>Тренируется такая модель через triplet loss. Каждый элемент в батче - 3 фото, 2 похожих, 3-я непохожая. Нужно найти такой loss, чтобы вектора похожих были ближе друг к другу, чем непохожая.</p><p><a href="https://www.youtube.com/watch?v=ajEQ10s8XRg&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=29m30s">29:30</a> - Unsupervised learning (обучение без учителя) - обучение на неразмеченных данных.</p><p>Вместо предсказывания алгоритм находит общее:</p><ul><li>выявление схожих характеристик (clustering)</li><li>выявление аномалий (outlier detection)</li><li>выучить фичу, которая пригодится в другой модели (learning features)</li><li>создание нового (generation)</li></ul><p>Чтобы обучить сеть созданию, нужно на выходе генерировать такую же картинку, как на входе. Надо построить её так, чтобы в середине сети было недостаточно ёмкости, чтобы сохранить всю информацию о пикселях. Для этого сети нужно будет понять высокоуровневые параметры картинки. Сеть делится на encoder и decoder (который делает upsampling).</p><p>Автоэнкодеры быстро приходят к overfitting. Чтобы это обойти, прибумали variational autoencoder (VAE). Энкодер вместо предсказания пикселя выдаёт среднее и сигму, дисперсию (грубо говоря, центр и радиус). А декодеру мы будем передавать случайную точку из области этого круга. Чтобы шарики не схлопнулись в точку, добавляют дополнительный loss, который заставляет сеть делать сигму как можно больше.</p><p>Сеть можно научить определённому вектору, например, наличию улыбки, наличию очков. Когда вектор получен, мы можем добавлять или вычитать его в других картинках.</p><p><a href="https://www.youtube.com/watch?v=ajEQ10s8XRg&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h00m00s">1:00:00</a> - Generative adversarial networks (GANs) или генеративно-состязательные сети. Состоят из 2 сетей. Геренатор должен из точки (случайный шум) дать картинку. Дискриминатор видит картинки генератора и картинки из датасета, он должен определять, реальная картинка или сгенерированная. Цели у сетей противоположные. Генератор должен научиться делать такие картинки, которые дискриминатор не распознает. Генератор имеет доступ к весам дискриминатора, поэтому он смотрит изнутри, как картинку определили.</p><p><a href=https://github.com/hindupuravinash/the-gan-zoo>GAN Zoo</a> - сотни ГАНов.</p><p>Современные: StyleGAN&rsquo;18</p><ul><li><a href=https://blog.inten.to/welcome-to-the-simulation-dd0d8cb6534d>Welcome to the Simulation</a></li><li><a href=https://github.com/clovaai/stargan-v2>StarGAN</a></li><li><a href=https://github.com/run-youngjoo/SC-FEGAN>SC-FEGAN</a></li><li><a href=https://generated.photos/faces>generated.photos</a></li><li><a href=https://github.com/NVlabs/stylegan2>StyleGAN</a></li></ul><h2 id=9-введение-в-nlp-word2vechttpswwwyoutubecomwatchvmbqdmquzmqmlistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex9><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=9">9. Введение в NLP, word2vec</a></h2><p>NLP сложно из-за того, что естественный язык сильно зависит от контекста. &ldquo;Он видел их семью своими глазами&rdquo;.</p><p><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=9m45s">9:45</a> - NLP pipleline</p><p><code>Вход</code> (текст, распознавание речи, OCR) -> <code>Морфология</code> (проверка текста, поиск по словам) -> <code>Синтаксис</code> (крутая проверка текста, парсинг) -> <code>Семантика</code> (положительное/отрицательное, sentiment analysis, машинный перевод) -> <code>Контекст</code> (связывание предложений).</p><p>Чем дальше по пайплайну, тем труднее составить список правил, чтобы формализовать обработку.</p><p><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=22m00s">22:00</a> - чтобы выразить задачу для нейросети, нужно перевести данные из символьного представления в непрерывное, то есть векторизовать. Как и в 8 уроке, в autoencoders, слова со схожим смыслом должны при этом оказаться ближе друг к другу и разбиться по кластерам.</p><p><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=30m30s">30:30</a> - word2vec - одно из первых успешных решений. Использует подход skip-gram: берёт соседние слова у каждого слова в датасете предложений, для каждого определяет вероятность использования соседних слов. Контекст вокруг слова - n-gram.</p><p>В архитектуре такой сети нет нелинейности (ReLu). Размеры матриц в слоях пропорциональны длине словаря.</p><p><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=51m10s">51:10</a> - Проблема с этим наступает на softmax, где система должна умножить каждое слово в словаре, а их могут быть миллионы. Чтобы это обойти, придумали negative sampling. При тренировке выбирают несколько случайных слов и выводят по ним бинарное предсказание вместо softmax.</p><p><a href="https://www.youtube.com/watch?v=MBQdMQUZMQM&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h08m00s">1:08:00</a> - FastText от Facebook, умеет определять вектора для новых слов: раскладывает слово на n-граммы, каждое векторизует, для новых слов берёт среднее из них, стоит брать эту модель для начала.</p><h2 id=10-recurrent-neural-networks-рекуррентные-нейронные-сетиhttpswwwyoutubecomwatchvtlj-cmibdmilistpl5fkq0af9o_o2eb5qn8pwcdg7tniyv1wbindex10><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&index=10">10. Recurrent Neural Networks, Рекуррентные нейронные сети</a></h2><p>У обычных сетей 1 вход и 1 выход. Бывают другие варианты:</p><ul><li>1 вход, много выходов</li><li>много входов, 1 выход (sentiment analysis)</li><li>переменные входы, переменные выходы (перевод текста)</li><li>много входов, столько же выходов</li></ul><p>Рекуррентная сеть умеет запоминать выход на слое и на следующем шаге передавать самой себе в будущее это значение на вход, вместе с инпутом. Внутри слоя вычисляется <code>h</code>: вход умножается на веса + предыдущий выход умножается на веса и берётся среднее (грубо говоря). На следующем шаге <code>h</code> переиспользуется.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=15m20s">15:20</a> - Пример: генерация текста. Модель принимает символы по одному (+ &ldquo;символы&rdquo; BOS, EOS, начало и конец), учим её предсказывать следующий символ. Размер вектора - кол-во символов в языке.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=34m50s">34:50</a> - Как тренируется RNN. Сеть &ldquo;разматывается&rdquo;, как будто один слой на разных шагах - разные слои.</p><p>Есть проблема: любой сигнал, умножаясь за 100 шагов на одну и ту же матрицу, становится очень большим. tanh его убьёт либо в 0, либо в 1, ReLu вообще нельзя использовать, т.к. значения уходят в небеса. Решают через long short-term memory (LSTM), в отличие от Vanilla RNN. Вместо 1 входа <code>h</code> делается 2 входа. <code>c</code> меняется по минимуму, чтобы градиенты протекали через него без экспоненциального изменения. В <code>h</code> добавляется несколько гейтов. Все гейты получают на вход конкатенацию векторов из <code>h</code> и <code>x</code>. Forget gate выдаёт вектор, равный размерности <code>c</code>, который говорит, сколько в <code>c</code> следует забыть. Input gate говорит, что нужно добавить (через tanh). Cell update говорит, что нужно передать на выход <code>c</code>. Output gate говорит, как нужно изменить значение <code>c</code>, чтобы выдать <code>h</code>. Это похоже на ResNet из 6 урока, где данные передавались без изменений через несколько слоёв.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=59m10s">59:10</a> - Bidirectional RNN</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h04m35s">1:04:35</a> - Пример разбора частей речи (part of speech tagging) с зависимостью от контекста. Решение: many to many, Bidirectional LSTM с дополнением (CRF models).</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h05m50s">1:05:50</a> - Нахождение именованных сущностей (named entity recognition, NER). Решение: many to many, Bidirectional LSTM CNN.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h06m50s">1:06:50</a> - Анализ тональности (sentiment analysis). Решение: many to one, LSTM.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h07m15s">1:07:15</a> - Машинный перевод (machine translation). Решение: many to many, LSTM.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h08m35s">1:08:35</a> - Использование в PyTorch.</p><p><a href="https://www.youtube.com/watch?v=tlj-CMibdMI&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=1h12m05s">1:12:05</a> - Разбор частей речи подробнее.</p><h2 id=ссылки>Ссылки</h2><p><a href=https://supervise.ly/>https://supervise.ly/</a> - сервис для разметки данных</p><blockquote><p>Чтобы заменять часы и минуты на ссылку с таймкодом, заменял в vscode <code>((\d+):(\d+)) -</code> на <code>[$1](https://www.youtube.com/watch?v=1BUuB28FDOc&list=PL5FkQ0AF9O_o2Eb5Qn8pwCDg7TniyV1Wb&t=$2m$3s) -</code></p></blockquote></div><footer><p class=meta><time itemprop=datePublished content="2020-04-12T22:51:00+0600">12 Apr 2020, 22:51</time>
<span class=categories>, теги:
<a class=category href=https://blog.popstas.ru/tags/ml>ML</a><meta itemprop=about content="ML"><a class=category href=https://blog.popstas.ru/tags/tensorflow>tensorflow</a><meta itemprop=about content="tensorflow"><a class=category href=https://blog.popstas.ru/tags/pytorch>pytorch</a><meta itemprop=about content="pytorch"></span></p><div class=sharing><div class="a2a_kit a2a_kit_size_32 a2a_default_style"><a href=https://www.addtoany.com/share></a><a class=a2a_button_facebook></a><a class=a2a_button_twitter></a><a class=a2a_button_google_plus></a><a class=a2a_button_vk></a><a class=a2a_button_pocket></a></div><script>var a2a_config=a2a_config||{};a2a_config.locale="ru";a2a_config.color_main="undefined";a2a_config.color_border="undefined";a2a_config.color_link_text="undefined";a2a_config.color_link_text_hover="undefined";a2a_config.color_bg="undefined";a2a_config.color_arrow="undefined";a2a_config.color_arrow_hover="undefined";a2a_config.prioritize=["facebook","twitter","google_plus","pocket","vk"];</script><script async src=https://static.addtoany.com/menu/page.js></script></div><p class=meta><div>Новее: <a class=related href=https://blog.popstas.ru/blog/2019/12/29/new-year-2019/ title="Итоги 2019 года">Итоги 2019 года</a></div><div>Старее: <a class=related href=https://blog.popstas.ru/blog/2020/04/13/yandex-dialogs-whatis/ title='Навык для Алисы "Вторая память": технические особенности'>Навык для Алисы "Вторая память": технические особенности</a></div></p></footer></article></div><aside class="sidebar thirds"><section class="first odd"><p>Обновления через <a href=https://tglink.ru/popstas_vk_wall>Telegram</a> или <a href=http://feeds.feedburner.com/popstas>RSS</a></p></section><ul class=sidebar-nav><li class=sidebar-nav-item><a target=_blank href=https://github.com/popstas/ title=https://github.com/popstas/><i class="fa fa-github fa-3x"></i></a><a target=_blank href=https://twitter.com/popstas/ title=https://twitter.com/popstas/><i class="fa fa-twitter fa-3x"></i></a><a target=_blank href="tg://resolve?domain=popstas" title=popstas><i class="fa fa-telegram fa-3x"></i></a><a target=_blank href=mailto:popstas@gmail.com title=popstas@gmail.com><i class="fa fa-at fa-3x"></i></a></li></ul><section class=even><div class=sidebar-title>Последние посты:</div><ul id=recent_posts><li class=post><a href=/navigator/>Навигатор</a></li><li class=post><a href=/blog/2020/05/20/den-arieli-predskazuemaya-irracionalnost/>Содержание книги Дэна Ариели «Предсказуемая иррациональность»</a></li><li class=post><a href=/blog/2020/04/16/books-70/>Мои книги: 7-й десяток: эволюция, продуктивность и дзен-буддизм</a></li><li class=post><a href=/blog/2020/04/15/npm-version/>NPM version: версионирование, история изменений, деплой проекта</a></li><li class=post><a href=/blog/2020/04/14/yandex-dialogs/>Яндекс.Диалоги: как я делал навыки для Алисы и инструменты для разработки</a></li><li class=post><a href=/blog/2020/04/13/yandex-dialogs-whatis/>Навык для Алисы "Вторая память": технические особенности</a></li><li class=post><a href=/blog/2020/04/12/deep-learning-ngu-2019/>Конспекты курса Deep Learning на пальцах 2019: таймкоды</a></li><li class=post><a href=/blog/2019/12/29/new-year-2019/>Итоги 2019 года</a></li><li class=post><a href=/blog/2019/12/29/books-2019/>Мои книги в 2019: 1-60: психология, бизнес, художка</a></li></ul></section></aside></div></div><footer role=contentinfo><p>Copyright &copy; 2015-2020 Stanislav Popov -
<span class=credit>Powered by <a target=_blank href=https://gohugo.io>Hugo</a> and <a target=_blank href=https://github.com/parsiya/hugo-octopress/>Hugo-Octopress</a> theme.</p></footer><script>(function(w,d,s,l,i){w[l]=w[l]||[];w[l].push({'gtm.start':new Date().getTime(),event:'gtm.js'});var f=d.getElementsByTagName(s)[0],j=d.createElement(s),dl=l!='dataLayer'?'&l='+l:'';j.async=true;j.src='https://www.googletagmanager.com/gtm.js?id='+i+dl;f.parentNode.insertBefore(j,f);})(window,document,'script','dataLayer','GTM-WPJWVXB');</script><script src=/js/custom.js></script><script type=text/javascript>(function(m,e,t,r,i,k,a){m[i]=m[i]||function(){(m[i].a=m[i].a||[]).push(arguments)};m[i].l=1*new Date();k=e.createElement(t),a=e.getElementsByTagName(t)[0],k.async=1,k.src=r,a.parentNode.insertBefore(k,a)})
(window,document,"script","https://mc.yandex.ru/metrika/tag.js","ym");ym(51681281,"init",{id:51681281,clickmap:true,trackLinks:true,accurateTrackBounce:true,webvisor:true});</script><noscript><div><img src=https://mc.yandex.ru/watch/51681281 style=position:absolute;left:-9999px alt></div></noscript></body></html>